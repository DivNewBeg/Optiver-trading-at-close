{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Agenda</b>\n",
    "1) Using pipelines\n",
    "<br>\n",
    "2) Construct plots\n",
    "<br>\n",
    "3) Improve performance\n",
    "<br>\n",
    "4) Push code into Github\n",
    "<br>\n",
    "<br>\n",
    "<b>Long-term goals</b>\n",
    "1) Loading data in batches\n",
    "<br>\n",
    "2) Parallel processing (perhaps using Apache Spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "papermill": {
     "duration": 12.871623,
     "end_time": "2023-12-09T13:00:25.746400",
     "exception": false,
     "start_time": "2023-12-09T13:00:12.874777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "papermill": {
     "duration": 14.270179,
     "end_time": "2023-12-09T13:00:40.021887",
     "exception": false,
     "start_time": "2023-12-09T13:00:25.751708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.004764,
     "end_time": "2023-12-09T13:00:40.032300",
     "exception": false,
     "start_time": "2023-12-09T13:00:40.027536",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1) View summary of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "papermill": {
     "duration": 0.012881,
     "end_time": "2023-12-09T13:00:40.050140",
     "exception": false,
     "start_time": "2023-12-09T13:00:40.037259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training data =  (5237980, 17)\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape of the training data = ', dataset_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "papermill": {
     "duration": 0.037969,
     "end_time": "2023-12-09T13:00:40.093386",
     "exception": false,
     "start_time": "2023-12-09T13:00:40.055417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows: -\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>date_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>imbalance_size</th>\n",
       "      <th>imbalance_buy_sell_flag</th>\n",
       "      <th>reference_price</th>\n",
       "      <th>matched_size</th>\n",
       "      <th>far_price</th>\n",
       "      <th>near_price</th>\n",
       "      <th>bid_price</th>\n",
       "      <th>bid_size</th>\n",
       "      <th>ask_price</th>\n",
       "      <th>ask_size</th>\n",
       "      <th>wap</th>\n",
       "      <th>target</th>\n",
       "      <th>time_id</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3180602.69</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>13380276.64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>60651.50</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>8493.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.029704</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166603.91</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>1642214.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>3233.04</td>\n",
       "      <td>1.000660</td>\n",
       "      <td>20605.09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.519986</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>302879.87</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999561</td>\n",
       "      <td>1819368.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>37956.00</td>\n",
       "      <td>1.000298</td>\n",
       "      <td>18995.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-8.389950</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11917682.27</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000171</td>\n",
       "      <td>18389745.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>2324.90</td>\n",
       "      <td>1.000214</td>\n",
       "      <td>479032.40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.010200</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>447549.96</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999532</td>\n",
       "      <td>17860614.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999394</td>\n",
       "      <td>16485.54</td>\n",
       "      <td>1.000016</td>\n",
       "      <td>434.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-7.349849</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stock_id  date_id  seconds_in_bucket  imbalance_size  \\\n",
       "0         0        0                  0      3180602.69   \n",
       "1         1        0                  0       166603.91   \n",
       "2         2        0                  0       302879.87   \n",
       "3         3        0                  0     11917682.27   \n",
       "4         4        0                  0       447549.96   \n",
       "\n",
       "   imbalance_buy_sell_flag  reference_price  matched_size  far_price  \\\n",
       "0                        1         0.999812   13380276.64        NaN   \n",
       "1                       -1         0.999896    1642214.25        NaN   \n",
       "2                       -1         0.999561    1819368.03        NaN   \n",
       "3                       -1         1.000171   18389745.62        NaN   \n",
       "4                       -1         0.999532   17860614.95        NaN   \n",
       "\n",
       "   near_price  bid_price  bid_size  ask_price   ask_size  wap    target  \\\n",
       "0         NaN   0.999812  60651.50   1.000026    8493.03  1.0 -3.029704   \n",
       "1         NaN   0.999896   3233.04   1.000660   20605.09  1.0 -5.519986   \n",
       "2         NaN   0.999403  37956.00   1.000298   18995.00  1.0 -8.389950   \n",
       "3         NaN   0.999999   2324.90   1.000214  479032.40  1.0 -4.010200   \n",
       "4         NaN   0.999394  16485.54   1.000016     434.10  1.0 -7.349849   \n",
       "\n",
       "   time_id row_id  \n",
       "0        0  0_0_0  \n",
       "1        0  0_0_1  \n",
       "2        0  0_0_2  \n",
       "3        0  0_0_3  \n",
       "4        0  0_0_4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('First 5 rows: -')\n",
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "papermill": {
     "duration": 2.651275,
     "end_time": "2023-12-09T13:00:42.750543",
     "exception": false,
     "start_time": "2023-12-09T13:00:40.099268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description of the data: -\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>date_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>imbalance_size</th>\n",
       "      <th>imbalance_buy_sell_flag</th>\n",
       "      <th>reference_price</th>\n",
       "      <th>matched_size</th>\n",
       "      <th>far_price</th>\n",
       "      <th>near_price</th>\n",
       "      <th>bid_price</th>\n",
       "      <th>bid_size</th>\n",
       "      <th>ask_price</th>\n",
       "      <th>ask_size</th>\n",
       "      <th>wap</th>\n",
       "      <th>target</th>\n",
       "      <th>time_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.237980e+06</td>\n",
       "      <td>5.237980e+06</td>\n",
       "      <td>5.237980e+06</td>\n",
       "      <td>5.237760e+06</td>\n",
       "      <td>5.237980e+06</td>\n",
       "      <td>5.237760e+06</td>\n",
       "      <td>5.237760e+06</td>\n",
       "      <td>2.343638e+06</td>\n",
       "      <td>2.380800e+06</td>\n",
       "      <td>5.237760e+06</td>\n",
       "      <td>5.237980e+06</td>\n",
       "      <td>5.237760e+06</td>\n",
       "      <td>5.237980e+06</td>\n",
       "      <td>5.237760e+06</td>\n",
       "      <td>5.237892e+06</td>\n",
       "      <td>5.237980e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.928856e+01</td>\n",
       "      <td>2.415100e+02</td>\n",
       "      <td>2.700000e+02</td>\n",
       "      <td>5.715293e+06</td>\n",
       "      <td>-1.189619e-02</td>\n",
       "      <td>9.999955e-01</td>\n",
       "      <td>4.510025e+07</td>\n",
       "      <td>1.001713e+00</td>\n",
       "      <td>9.996601e-01</td>\n",
       "      <td>9.997263e-01</td>\n",
       "      <td>5.181359e+04</td>\n",
       "      <td>1.000264e+00</td>\n",
       "      <td>5.357568e+04</td>\n",
       "      <td>9.999920e-01</td>\n",
       "      <td>-4.756125e-02</td>\n",
       "      <td>1.331005e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.787176e+01</td>\n",
       "      <td>1.385319e+02</td>\n",
       "      <td>1.587451e+02</td>\n",
       "      <td>2.051591e+07</td>\n",
       "      <td>8.853374e-01</td>\n",
       "      <td>2.532497e-03</td>\n",
       "      <td>1.398413e+08</td>\n",
       "      <td>7.214705e-01</td>\n",
       "      <td>1.216920e-02</td>\n",
       "      <td>2.499345e-03</td>\n",
       "      <td>1.114214e+05</td>\n",
       "      <td>2.510042e-03</td>\n",
       "      <td>1.293554e+05</td>\n",
       "      <td>2.497509e-03</td>\n",
       "      <td>9.452860e+00</td>\n",
       "      <td>7.619271e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>9.352850e-01</td>\n",
       "      <td>4.316610e+03</td>\n",
       "      <td>7.700000e-05</td>\n",
       "      <td>7.869880e-01</td>\n",
       "      <td>9.349150e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.398270e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.380080e-01</td>\n",
       "      <td>-3.852898e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.900000e+01</td>\n",
       "      <td>1.220000e+02</td>\n",
       "      <td>1.300000e+02</td>\n",
       "      <td>8.453415e+04</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>9.987630e-01</td>\n",
       "      <td>5.279575e+06</td>\n",
       "      <td>9.963320e-01</td>\n",
       "      <td>9.971000e-01</td>\n",
       "      <td>9.985290e-01</td>\n",
       "      <td>7.374720e+03</td>\n",
       "      <td>9.990290e-01</td>\n",
       "      <td>7.823700e+03</td>\n",
       "      <td>9.987810e-01</td>\n",
       "      <td>-4.559755e+00</td>\n",
       "      <td>6.729000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.900000e+01</td>\n",
       "      <td>2.420000e+02</td>\n",
       "      <td>2.700000e+02</td>\n",
       "      <td>1.113604e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.999670e-01</td>\n",
       "      <td>1.288264e+07</td>\n",
       "      <td>9.998830e-01</td>\n",
       "      <td>9.998890e-01</td>\n",
       "      <td>9.997280e-01</td>\n",
       "      <td>2.196900e+04</td>\n",
       "      <td>1.000207e+00</td>\n",
       "      <td>2.301792e+04</td>\n",
       "      <td>9.999970e-01</td>\n",
       "      <td>-6.020069e-02</td>\n",
       "      <td>1.334500e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.490000e+02</td>\n",
       "      <td>3.610000e+02</td>\n",
       "      <td>4.100000e+02</td>\n",
       "      <td>4.190951e+06</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.001174e+00</td>\n",
       "      <td>3.270013e+07</td>\n",
       "      <td>1.003318e+00</td>\n",
       "      <td>1.002590e+00</td>\n",
       "      <td>1.000905e+00</td>\n",
       "      <td>5.583168e+04</td>\n",
       "      <td>1.001414e+00</td>\n",
       "      <td>5.787841e+04</td>\n",
       "      <td>1.001149e+00</td>\n",
       "      <td>4.409552e+00</td>\n",
       "      <td>1.990700e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.990000e+02</td>\n",
       "      <td>4.800000e+02</td>\n",
       "      <td>5.400000e+02</td>\n",
       "      <td>2.982028e+09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.077488e+00</td>\n",
       "      <td>7.713682e+09</td>\n",
       "      <td>4.379531e+02</td>\n",
       "      <td>1.309732e+00</td>\n",
       "      <td>1.077488e+00</td>\n",
       "      <td>3.028784e+07</td>\n",
       "      <td>1.077836e+00</td>\n",
       "      <td>5.440500e+07</td>\n",
       "      <td>1.077675e+00</td>\n",
       "      <td>4.460704e+02</td>\n",
       "      <td>2.645400e+04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           stock_id       date_id  seconds_in_bucket  imbalance_size  \\\n",
       "count  5.237980e+06  5.237980e+06       5.237980e+06    5.237760e+06   \n",
       "mean   9.928856e+01  2.415100e+02       2.700000e+02    5.715293e+06   \n",
       "std    5.787176e+01  1.385319e+02       1.587451e+02    2.051591e+07   \n",
       "min    0.000000e+00  0.000000e+00       0.000000e+00    0.000000e+00   \n",
       "25%    4.900000e+01  1.220000e+02       1.300000e+02    8.453415e+04   \n",
       "50%    9.900000e+01  2.420000e+02       2.700000e+02    1.113604e+06   \n",
       "75%    1.490000e+02  3.610000e+02       4.100000e+02    4.190951e+06   \n",
       "max    1.990000e+02  4.800000e+02       5.400000e+02    2.982028e+09   \n",
       "\n",
       "       imbalance_buy_sell_flag  reference_price  matched_size     far_price  \\\n",
       "count             5.237980e+06     5.237760e+06  5.237760e+06  2.343638e+06   \n",
       "mean             -1.189619e-02     9.999955e-01  4.510025e+07  1.001713e+00   \n",
       "std               8.853374e-01     2.532497e-03  1.398413e+08  7.214705e-01   \n",
       "min              -1.000000e+00     9.352850e-01  4.316610e+03  7.700000e-05   \n",
       "25%              -1.000000e+00     9.987630e-01  5.279575e+06  9.963320e-01   \n",
       "50%               0.000000e+00     9.999670e-01  1.288264e+07  9.998830e-01   \n",
       "75%               1.000000e+00     1.001174e+00  3.270013e+07  1.003318e+00   \n",
       "max               1.000000e+00     1.077488e+00  7.713682e+09  4.379531e+02   \n",
       "\n",
       "         near_price     bid_price      bid_size     ask_price      ask_size  \\\n",
       "count  2.380800e+06  5.237760e+06  5.237980e+06  5.237760e+06  5.237980e+06   \n",
       "mean   9.996601e-01  9.997263e-01  5.181359e+04  1.000264e+00  5.357568e+04   \n",
       "std    1.216920e-02  2.499345e-03  1.114214e+05  2.510042e-03  1.293554e+05   \n",
       "min    7.869880e-01  9.349150e-01  0.000000e+00  9.398270e-01  0.000000e+00   \n",
       "25%    9.971000e-01  9.985290e-01  7.374720e+03  9.990290e-01  7.823700e+03   \n",
       "50%    9.998890e-01  9.997280e-01  2.196900e+04  1.000207e+00  2.301792e+04   \n",
       "75%    1.002590e+00  1.000905e+00  5.583168e+04  1.001414e+00  5.787841e+04   \n",
       "max    1.309732e+00  1.077488e+00  3.028784e+07  1.077836e+00  5.440500e+07   \n",
       "\n",
       "                wap        target       time_id  \n",
       "count  5.237760e+06  5.237892e+06  5.237980e+06  \n",
       "mean   9.999920e-01 -4.756125e-02  1.331005e+04  \n",
       "std    2.497509e-03  9.452860e+00  7.619271e+03  \n",
       "min    9.380080e-01 -3.852898e+02  0.000000e+00  \n",
       "25%    9.987810e-01 -4.559755e+00  6.729000e+03  \n",
       "50%    9.999970e-01 -6.020069e-02  1.334500e+04  \n",
       "75%    1.001149e+00  4.409552e+00  1.990700e+04  \n",
       "max    1.077675e+00  4.460704e+02  2.645400e+04  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Description of the data: -')\n",
    "dataset_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.005217,
     "end_time": "2023-12-09T13:00:42.761610",
     "exception": false,
     "start_time": "2023-12-09T13:00:42.756393",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2) Handling missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.00515,
     "end_time": "2023-12-09T13:00:42.772122",
     "exception": false,
     "start_time": "2023-12-09T13:00:42.766972",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.1) Determine missingness in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "papermill": {
     "duration": 0.230836,
     "end_time": "2023-12-09T13:00:43.009255",
     "exception": false,
     "start_time": "2023-12-09T13:00:42.778419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of missing values for various columns of the dataframe: -\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "stock_id                    0.000000\n",
       "date_id                     0.000000\n",
       "seconds_in_bucket           0.000000\n",
       "imbalance_size              0.004200\n",
       "imbalance_buy_sell_flag     0.000000\n",
       "reference_price             0.004200\n",
       "matched_size                0.004200\n",
       "far_price                  55.256836\n",
       "near_price                 54.547364\n",
       "bid_price                   0.004200\n",
       "bid_size                    0.000000\n",
       "ask_price                   0.004200\n",
       "ask_size                    0.000000\n",
       "wap                         0.004200\n",
       "target                      0.001680\n",
       "time_id                     0.000000\n",
       "row_id                      0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"List of missing values for various columns of the dataframe: -\")\n",
    "num_missing_vals_series = (dataset_df.isnull().sum(axis = 0)/dataset_df.shape[0]) * 100\n",
    "num_missing_vals_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "papermill": {
     "duration": 1.306441,
     "end_time": "2023-12-09T13:00:44.321862",
     "exception": false,
     "start_time": "2023-12-09T13:00:43.015421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature = imbalance_size\n",
      "Percentage of missing values = 0.004200092402032845\n",
      "Dropping missing values for imbalance_size\n",
      "\n",
      "\n",
      "Feature = reference_price\n",
      "Percentage of missing values = 0.004200092402032845\n",
      "Dropping missing values for reference_price\n",
      "\n",
      "\n",
      "Feature = matched_size\n",
      "Percentage of missing values = 0.004200092402032845\n",
      "Dropping missing values for matched_size\n",
      "\n",
      "\n",
      "Feature = bid_price\n",
      "Percentage of missing values = 0.004200092402032845\n",
      "Dropping missing values for bid_price\n",
      "\n",
      "\n",
      "Feature = ask_price\n",
      "Percentage of missing values = 0.004200092402032845\n",
      "Dropping missing values for ask_price\n",
      "\n",
      "\n",
      "Feature = wap\n",
      "Percentage of missing values = 0.004200092402032845\n",
      "Dropping missing values for wap\n",
      "\n",
      "\n",
      "Feature = target\n",
      "Percentage of missing values = 0.0016800369608131378\n",
      "Dropping missing values for target\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "\n",
    "for feature in num_missing_vals_series.index:\n",
    "    \n",
    "    if (num_missing_vals_series[feature] > 0) and (num_missing_vals_series[feature] < 1):\n",
    "        print(f'Feature = {feature}')\n",
    "        print(f'Percentage of missing values = {num_missing_vals_series[feature]}')\n",
    "        print(f'Dropping missing values for {feature}')\n",
    "        dataset_df.dropna(subset = feature, inplace = True)\n",
    "        print('\\n')\n",
    "    \n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "papermill": {
     "duration": 0.225137,
     "end_time": "2023-12-09T13:00:44.553295",
     "exception": false,
     "start_time": "2023-12-09T13:00:44.328158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stock_id                    0.000000\n",
       "date_id                     0.000000\n",
       "seconds_in_bucket           0.000000\n",
       "imbalance_size              0.000000\n",
       "imbalance_buy_sell_flag     0.000000\n",
       "reference_price             0.000000\n",
       "matched_size                0.000000\n",
       "far_price                  55.254956\n",
       "near_price                 54.545455\n",
       "bid_price                   0.000000\n",
       "bid_size                    0.000000\n",
       "ask_price                   0.000000\n",
       "ask_size                    0.000000\n",
       "wap                         0.000000\n",
       "target                      0.000000\n",
       "time_id                     0.000000\n",
       "row_id                      0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_missing_vals_series = (dataset_df.isnull().sum(axis = 0)/dataset_df.shape[0]) * 100\n",
    "num_missing_vals_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "papermill": {
     "duration": 0.683563,
     "end_time": "2023-12-09T13:00:45.243047",
     "exception": false,
     "start_time": "2023-12-09T13:00:44.559484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_df.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "papermill": {
     "duration": 0.228316,
     "end_time": "2023-12-09T13:00:45.478875",
     "exception": false,
     "start_time": "2023-12-09T13:00:45.250559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stock_id                   0.0\n",
       "date_id                    0.0\n",
       "seconds_in_bucket          0.0\n",
       "imbalance_size             0.0\n",
       "imbalance_buy_sell_flag    0.0\n",
       "reference_price            0.0\n",
       "matched_size               0.0\n",
       "far_price                  0.0\n",
       "near_price                 0.0\n",
       "bid_price                  0.0\n",
       "bid_size                   0.0\n",
       "ask_price                  0.0\n",
       "ask_size                   0.0\n",
       "wap                        0.0\n",
       "target                     0.0\n",
       "time_id                    0.0\n",
       "row_id                     0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_missing_vals_series = (dataset_df.isnull().sum(axis = 0)/dataset_df.shape[0]) * 100\n",
    "num_missing_vals_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.005862,
     "end_time": "2023-12-09T13:00:45.491222",
     "exception": false,
     "start_time": "2023-12-09T13:00:45.485360",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3) Reshaping and preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_reshaped_df = dataset_df\n",
    "dataset_reshaped_df.sort_values(by = ['stock_id', 'date_id', 'seconds_in_bucket'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_features(df):\n",
    "    \n",
    "    df['imbalance_size'] = df['imbalance_size'] * df['imbalance_buy_sell_flag']\n",
    "\n",
    "def compute_rollover_features(df):\n",
    "    \n",
    "    df['prev_target'] = df.groupby('stock_id')['target'].shift(1)\n",
    "    df.fillna(0, inplace = True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def standardize_features(df, mu_dict=None, sigma_dict=None):\n",
    "    \n",
    "    if (mu_dict is None) and (sigma_dict is None):\n",
    "        \n",
    "        mu_dict = {}\n",
    "        sigma_dict = {}\n",
    "        \n",
    "        mu_dict['imbalance_size'] = [0]*200\n",
    "        mu_dict['reference_price'] = [0]*200\n",
    "        mu_dict['matched_size'] = [0]*200\n",
    "        mu_dict['far_price'] = [0]*200\n",
    "        mu_dict['near_price'] = [0]*200\n",
    "        mu_dict['bid_price'] = [0]*200\n",
    "        mu_dict['bid_size'] = [0]*200\n",
    "        mu_dict['ask_price'] = [0]*200\n",
    "        mu_dict['ask_size'] = [0]*200\n",
    "        mu_dict['wap'] = [0]*200\n",
    "        mu_dict['prev_target'] = [0]*200\n",
    "        \n",
    "        sigma_dict['imbalance_size'] = [0]*200\n",
    "        sigma_dict['reference_price'] = [0]*200\n",
    "        sigma_dict['matched_size'] = [0]*200\n",
    "        sigma_dict['far_price'] = [0]*200\n",
    "        sigma_dict['near_price'] = [0]*200\n",
    "        sigma_dict['bid_price'] = [0]*200\n",
    "        sigma_dict['bid_size'] = [0]*200\n",
    "        sigma_dict['ask_price'] = [0]*200\n",
    "        sigma_dict['ask_size'] = [0]*200\n",
    "        sigma_dict['wap'] = [0]*200\n",
    "        sigma_dict['prev_target'] = [0]*200\n",
    "        \n",
    "        for stock_id in range(df['stock_id'].max()+1):\n",
    "            \n",
    "            mu_dict['imbalance_size'][stock_id] = df[df['stock_id'] == stock_id]['imbalance_size'].mean()\n",
    "            mu_dict['reference_price'][stock_id] = df[df['stock_id'] == stock_id]['reference_price'].mean()\n",
    "            mu_dict['matched_size'][stock_id] = df[df['stock_id'] == stock_id]['matched_size'].mean()\n",
    "            mu_dict['far_price'][stock_id] = df[df['stock_id'] == stock_id]['far_price'].mean()\n",
    "            mu_dict['near_price'][stock_id] = df[df['stock_id'] == stock_id]['near_price'].mean()\n",
    "            mu_dict['bid_price'][stock_id] = df[df['stock_id'] == stock_id]['bid_price'].mean()\n",
    "            mu_dict['bid_size'][stock_id] = df[df['stock_id'] == stock_id]['bid_size'].mean()\n",
    "            mu_dict['ask_price'][stock_id] = df[df['stock_id'] == stock_id]['ask_price'].mean()\n",
    "            mu_dict['ask_size'][stock_id] = df[df['stock_id'] == stock_id]['ask_size'].mean()\n",
    "            mu_dict['wap'][stock_id] = df[df['stock_id'] == stock_id]['wap'].mean()\n",
    "            mu_dict['prev_target'][stock_id] = df[df['stock_id'] == stock_id]['prev_target'].mean()\n",
    "            \n",
    "            sigma_dict['imbalance_size'][stock_id] = df[df['stock_id'] == stock_id]['imbalance_size'].std()\n",
    "            sigma_dict['reference_price'][stock_id] = df[df['stock_id'] == stock_id]['reference_price'].std()\n",
    "            sigma_dict['matched_size'][stock_id] = df[df['stock_id'] == stock_id]['matched_size'].std()\n",
    "            sigma_dict['far_price'][stock_id] = df[df['stock_id'] == stock_id]['far_price'].std()\n",
    "            sigma_dict['near_price'][stock_id] = df[df['stock_id'] == stock_id]['near_price'].std()\n",
    "            sigma_dict['bid_price'][stock_id] = df[df['stock_id'] == stock_id]['bid_price'].std()\n",
    "            sigma_dict['bid_size'][stock_id] = df[df['stock_id'] == stock_id]['bid_size'].std()\n",
    "            sigma_dict['ask_price'][stock_id] = df[df['stock_id'] == stock_id]['ask_price'].std()\n",
    "            sigma_dict['ask_size'][stock_id] = df[df['stock_id'] == stock_id]['ask_size'].std()\n",
    "            sigma_dict['wap'][stock_id] = df[df['stock_id'] == stock_id]['wap'].std()\n",
    "            sigma_dict['prev_target'][stock_id] = df[df['stock_id'] == stock_id]['prev_target'].std()\n",
    "    \n",
    "    df['imbalance_size'] = (df['imbalance_size'] - df['stock_id'].map(lambda x: mu_dict['imbalance_size'][x]))/df['stock_id'].map(lambda x: sigma_dict['imbalance_size'][x])\n",
    "    df['reference_price'] = (df['reference_price'] - df['stock_id'].map(lambda x: mu_dict['reference_price'][x]))/df['stock_id'].map(lambda x: sigma_dict['reference_price'][x])\n",
    "    df['matched_size'] = (df['matched_size'] - df['stock_id'].map(lambda x: mu_dict['matched_size'][x]))/df['stock_id'].map(lambda x: sigma_dict['matched_size'][x])\n",
    "    df['far_price'] = (df['far_price'] - df['stock_id'].map(lambda x: mu_dict['far_price'][x]))/df['stock_id'].map(lambda x: sigma_dict['far_price'][x])\n",
    "    df['near_price'] = (df['near_price'] - df['stock_id'].map(lambda x: mu_dict['near_price'][x]))/df['stock_id'].map(lambda x: sigma_dict['near_price'][x])\n",
    "    df['bid_price'] = (df['bid_price'] - df['stock_id'].map(lambda x: mu_dict['bid_price'][x]))/df['stock_id'].map(lambda x: sigma_dict['bid_price'][x])\n",
    "    df['bid_size'] = (df['bid_size'] - df['stock_id'].map(lambda x: mu_dict['bid_size'][x]))/df['stock_id'].map(lambda x: sigma_dict['bid_size'][x])\n",
    "    df['ask_price'] = (df['ask_price'] - df['stock_id'].map(lambda x: mu_dict['ask_price'][x]))/df['stock_id'].map(lambda x: sigma_dict['ask_price'][x])\n",
    "    df['ask_size'] = (df['ask_size'] - df['stock_id'].map(lambda x: mu_dict['ask_size'][x]))/df['stock_id'].map(lambda x: sigma_dict['ask_size'][x])    \n",
    "    df['wap'] = (df['wap'] - df['stock_id'].map(lambda x: mu_dict['wap'][x]))/df['stock_id'].map(lambda x: sigma_dict['wap'][x])        \n",
    "        \n",
    "    df['prev_target'] = (df['prev_target'] - df['stock_id'].map(lambda x: mu_dict['prev_target'][x]))/df['stock_id'].map(lambda x: sigma_dict['prev_target'][x])\n",
    "    \n",
    "    return (mu_dict, sigma_dict)\n",
    "   \n",
    "def drop_features(df):\n",
    "    \n",
    "    #Drop the following features.\n",
    "    df.drop(['row_id', 'imbalance_buy_sell_flag'], axis = 1, inplace = True)\n",
    "    \n",
    "    if 'currently_scored' in df.columns:\n",
    "        df.drop(['currently_scored'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recompute some features.\n",
    "compute_features(dataset_reshaped_df)\n",
    "\n",
    "#Compute roll-over features.\n",
    "dataset_reshaped_df = compute_rollover_features(dataset_reshaped_df)\n",
    "\n",
    "#Standardize features.\n",
    "mu_dict, sigma_dict = standardize_features(dataset_reshaped_df)\n",
    "\n",
    "#Drop features from the dataset.\n",
    "drop_features(dataset_reshaped_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>date_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>imbalance_size</th>\n",
       "      <th>reference_price</th>\n",
       "      <th>matched_size</th>\n",
       "      <th>far_price</th>\n",
       "      <th>near_price</th>\n",
       "      <th>bid_price</th>\n",
       "      <th>bid_size</th>\n",
       "      <th>ask_price</th>\n",
       "      <th>ask_size</th>\n",
       "      <th>wap</th>\n",
       "      <th>target</th>\n",
       "      <th>time_id</th>\n",
       "      <th>prev_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.420313</td>\n",
       "      <td>-0.013518</td>\n",
       "      <td>-0.587909</td>\n",
       "      <td>-0.906572</td>\n",
       "      <td>-0.912704</td>\n",
       "      <td>0.045702</td>\n",
       "      <td>0.326687</td>\n",
       "      <td>0.042624</td>\n",
       "      <td>-0.517844</td>\n",
       "      <td>0.094030</td>\n",
       "      <td>-3.029704</td>\n",
       "      <td>0</td>\n",
       "      <td>0.043116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.218021</td>\n",
       "      <td>0.113973</td>\n",
       "      <td>-0.498553</td>\n",
       "      <td>-0.906572</td>\n",
       "      <td>-0.912704</td>\n",
       "      <td>0.045702</td>\n",
       "      <td>-0.292750</td>\n",
       "      <td>0.042624</td>\n",
       "      <td>-0.257284</td>\n",
       "      <td>0.029652</td>\n",
       "      <td>0.389814</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.457311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.218021</td>\n",
       "      <td>0.050228</td>\n",
       "      <td>-0.498553</td>\n",
       "      <td>-0.906572</td>\n",
       "      <td>-0.912704</td>\n",
       "      <td>0.045702</td>\n",
       "      <td>-0.416637</td>\n",
       "      <td>-0.021117</td>\n",
       "      <td>-0.454750</td>\n",
       "      <td>-0.000153</td>\n",
       "      <td>4.220009</td>\n",
       "      <td>2</td>\n",
       "      <td>0.107503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0.218021</td>\n",
       "      <td>0.177718</td>\n",
       "      <td>-0.498553</td>\n",
       "      <td>-0.906572</td>\n",
       "      <td>-0.912704</td>\n",
       "      <td>0.173495</td>\n",
       "      <td>0.264903</td>\n",
       "      <td>0.106365</td>\n",
       "      <td>0.136070</td>\n",
       "      <td>0.144697</td>\n",
       "      <td>5.450249</td>\n",
       "      <td>3</td>\n",
       "      <td>0.740151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.209248</td>\n",
       "      <td>0.369550</td>\n",
       "      <td>-0.494678</td>\n",
       "      <td>-0.906572</td>\n",
       "      <td>-0.912704</td>\n",
       "      <td>0.301885</td>\n",
       "      <td>-0.283994</td>\n",
       "      <td>0.298183</td>\n",
       "      <td>-0.203679</td>\n",
       "      <td>0.282991</td>\n",
       "      <td>3.169775</td>\n",
       "      <td>4</td>\n",
       "      <td>0.943354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     stock_id  date_id  seconds_in_bucket  imbalance_size  reference_price  \\\n",
       "0           0        0                  0        0.420313        -0.013518   \n",
       "191         0        0                 10        0.218021         0.113973   \n",
       "382         0        0                 20        0.218021         0.050228   \n",
       "573         0        0                 30        0.218021         0.177718   \n",
       "764         0        0                 40        0.209248         0.369550   \n",
       "\n",
       "     matched_size  far_price  near_price  bid_price  bid_size  ask_price  \\\n",
       "0       -0.587909  -0.906572   -0.912704   0.045702  0.326687   0.042624   \n",
       "191     -0.498553  -0.906572   -0.912704   0.045702 -0.292750   0.042624   \n",
       "382     -0.498553  -0.906572   -0.912704   0.045702 -0.416637  -0.021117   \n",
       "573     -0.498553  -0.906572   -0.912704   0.173495  0.264903   0.106365   \n",
       "764     -0.494678  -0.906572   -0.912704   0.301885 -0.283994   0.298183   \n",
       "\n",
       "     ask_size       wap    target  time_id  prev_target  \n",
       "0   -0.517844  0.094030 -3.029704        0     0.043116  \n",
       "191 -0.257284  0.029652  0.389814        1    -0.457311  \n",
       "382 -0.454750 -0.000153  4.220009        2     0.107503  \n",
       "573  0.136070  0.144697  5.450249        3     0.740151  \n",
       "764 -0.203679  0.282991  3.169775        4     0.943354  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_reshaped_df[dataset_reshaped_df['stock_id'] == 0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = dataset_reshaped_df[dataset_reshaped_df['date_id'] < 478]\n",
    "val_df = dataset_reshaped_df[dataset_reshaped_df['date_id'] >= 478]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 7746, 11) (1, 7746, 1)\n"
     ]
    }
   ],
   "source": [
    "def get_training_data(stock_id, test_val_data_dates, threshold = 0.9):\n",
    "    \n",
    "    #Get all training data associated with the stock_id.\n",
    "    stock_train_df = train_df[train_df['stock_id'] == stock_id].copy()\n",
    "    \n",
    "    #Drop columns not relevant for the cosine similarity and convert the result to arrays.\n",
    "    train_curr_date_array = stock_train_df.drop(['stock_id', 'target', 'date_id', 'time_id', 'seconds_in_bucket'], axis = 1).values\n",
    "    train_target_date_array = (stock_train_df['target'].values).reshape(-1, 1)\n",
    "    \n",
    "    indices_of_closest_arrays = None\n",
    "    \n",
    "    for test_val_data_date in test_val_data_dates:\n",
    "        \n",
    "        #print(train_curr_date_array.shape, test_val_data_date.shape)\n",
    "    \n",
    "        #Compute the cosine similarity between the single row of test data and the all the rows of training data.\n",
    "        cos_sim = cosine_similarity(train_curr_date_array, test_val_data_date.reshape(1, -1))\n",
    "        \n",
    "        if indices_of_closest_arrays is None:\n",
    "            #Determine the indices of training data with higher cosine similarity than the threshold.\n",
    "            indices_of_closest_arrays = np.where(cos_sim > threshold)[0]\n",
    "        \n",
    "        else:\n",
    "            indices_of_closest_arrays = np.concatenate((indices_of_closest_arrays, np.where(cos_sim > threshold)[0]))\n",
    "    \n",
    "    indices_of_closest_arrays = np.unique(indices_of_closest_arrays)\n",
    "    indices_of_closest_arrays = np.sort(indices_of_closest_arrays)\n",
    "    \n",
    "    #Get training rows corressponding to the indices determined earlier.\n",
    "    ret_train_arr = train_curr_date_array[indices_of_closest_arrays]\n",
    "    ret_train_arr = ret_train_arr.reshape(1, ret_train_arr.shape[0], ret_train_arr.shape[1])\n",
    "    \n",
    "    #Get target values for the training rows determined earlier.\n",
    "    ret_train_tar_arr = train_target_date_array[indices_of_closest_arrays]\n",
    "    ret_train_tar_arr = ret_train_tar_arr.reshape(1, ret_train_tar_arr.shape[0], ret_train_tar_arr.shape[1])\n",
    "    \n",
    "    return ret_train_arr, ret_train_tar_arr\n",
    "\n",
    "#& (val_df['seconds_in_bucket'] == 0)\n",
    "tr_array = get_training_data(2, val_df[(val_df['stock_id'] == 2) & (val_df['date_id'] == 478)].drop(['stock_id', 'target', 'date_id', 'time_id', 'seconds_in_bucket', 'target'], axis = 1).values, threshold = 0.9)\n",
    "print(tr_array[0].shape, tr_array[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(165, 11) (165, 11)\n"
     ]
    }
   ],
   "source": [
    "def get_valid_test_data(stock_id, seq_len = 100):\n",
    "    \n",
    "    test_val_df = val_df[val_df['stock_id'] == stock_id].copy()\n",
    "    test_val_df.drop(['stock_id', 'date_id', 'time_id', 'seconds_in_bucket'], inplace = True, axis = 1)\n",
    "    \n",
    "    val_target_array = None\n",
    "    \n",
    "    if 'target' in test_val_df.columns:\n",
    "        val_target_array = (test_val_df['target'].values).reshape(-1, 1)\n",
    "        test_val_df.drop(['target'], inplace = True, axis = 1)\n",
    "    \n",
    "    val_array = test_val_df.values\n",
    "    val_target_array = val_target_array\n",
    "    \n",
    "    return val_array, val_target_array\n",
    "\n",
    "tr_array = get_valid_test_data(0, seq_len = 2000)\n",
    "print(tr_array[0].shape, tr_array[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.006254,
     "end_time": "2023-12-09T13:00:48.204085",
     "exception": false,
     "start_time": "2023-12-09T13:00:48.197831",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4) Creating models specific to each stock ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "papermill": {
     "duration": 0.015892,
     "end_time": "2023-12-09T13:00:48.226079",
     "exception": false,
     "start_time": "2023-12-09T13:00:48.210187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Function declarations\n",
    "def step_decay(epoch, learning_rate):\n",
    "    # initialize the base initial learning rate, drop factor, and epochs to drop every\n",
    "    init_lr = 1\n",
    "    factor = 0.9\n",
    "    drop_every = 6\n",
    "    # compute learning rate for the current epoch\n",
    "    learning_rate = init_lr*(factor ** (np.floor(epoch) / drop_every))\n",
    "    return learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size = 11\n"
     ]
    }
   ],
   "source": [
    "#Input dimension - 1 has been added because 'PREV_TARGET field is introduced much later'\n",
    "INPUT_SIZE = 11\n",
    "print(f'Input size = {INPUT_SIZE}')\n",
    "\n",
    "#Declaring a dictionary of models - a model for each stock ID.\n",
    "models_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(threshold):\n",
    "    \n",
    "    early_checkpoint = EarlyStopping(patience=2, monitor='mae', mode='min')\n",
    "\n",
    "    seed_value = 42\n",
    "    tf.random.set_seed(seed_value)\n",
    "\n",
    "    #Construct train/validation sets separately for all stock IDs.\n",
    "    for curr_stock_id in dataset_reshaped_df['stock_id'].unique():\n",
    "        \n",
    "        print(f'Training model for stock ID {curr_stock_id}')\n",
    "        \n",
    "        curr_train_mae = 0\n",
    "        curr_val_mae = 0\n",
    "        \n",
    "        #Get validation data (numpy array) for the current stock_id.\n",
    "        curr_stock_val_data = get_valid_test_data(curr_stock_id, INPUT_SIZE)\n",
    "        \n",
    "        #Construct a GRU model for the current stock ID.\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.GRU(8, return_sequences=True, input_shape=(None, INPUT_SIZE)),\n",
    "            tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(1, activation='linear'))])\n",
    "        \n",
    "        #Compile the model.\n",
    "        lr_scheduler = keras.callbacks.LearningRateScheduler(step_decay)\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "        model.compile(loss=\"mean_absolute_error\", optimizer=opt, metrics=[\"mae\"])\n",
    "        \n",
    "        #Get training data (numpy array) corressponding to the current test row.\n",
    "        curr_test_row = val_df[val_df['stock_id'] == curr_stock_id].drop(['stock_id', 'target', 'date_id', 'time_id', 'seconds_in_bucket', 'target'], axis = 1).values\n",
    "        curr_stock_train_data = get_training_data(curr_stock_id, curr_test_row, threshold = threshold)    \n",
    "        \n",
    "        if curr_stock_train_data[0].shape[1] == 0:\n",
    "            curr_stock_train_data = get_training_data(curr_stock_id, curr_test_row, threshold = 0.8)\n",
    "        elif curr_stock_train_data[0].shape[1] == 0:\n",
    "            curr_stock_train_data = get_training_data(curr_stock_id, curr_test_row, threshold = 0.7)\n",
    "        else:\n",
    "            curr_stock_train_data = get_training_data(curr_stock_id, curr_test_row, threshold = 0.6)\n",
    "        \n",
    "        #Create training dataset.\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((curr_stock_train_data[0], curr_stock_train_data[1]))\n",
    "        train_dataset = train_dataset.batch(500)\n",
    "        \n",
    "        #Create validation dataset.\n",
    "        val_dataset = tf.data.Dataset.from_tensor_slices((curr_stock_val_data[0].reshape(1, 165, 11), curr_stock_val_data[1].reshape(1, 165, 1)))\n",
    "        val_dataset = val_dataset.batch(500)\n",
    "        \n",
    "        #Train the model.\n",
    "        history = model.fit(train_dataset, validation_data = val_dataset, epochs=20, callbacks=[early_checkpoint, lr_scheduler], verbose = 1)\n",
    "            \n",
    "        #Determine the cumulative training and validation MAEs across the different rows of the validation\n",
    "        #data.\n",
    "        curr_train_mae = history.history['mae'][-1]\n",
    "        curr_val_mae = history.history['val_mae'][-1]\n",
    "        \n",
    "        print(f'Stock ID = {curr_stock_id}, Threshold = {threshold}, Training MAE = {curr_train_mae}, Validation MAE = {curr_val_mae}')\n",
    "        \n",
    "        if curr_stock_id not in models_dict.keys():\n",
    "            models_dict[curr_stock_id] = [model, threshold, curr_train_mae, curr_val_mae]\n",
    "        \n",
    "        else:\n",
    "            if models_dict[curr_stock_id][3] > curr_val_mae:\n",
    "                models_dict[curr_stock_id][0] = model\n",
    "                models_dict[curr_stock_id][1] = threshold   \n",
    "                models_dict[curr_stock_id][2] = curr_train_mae\n",
    "                models_dict[curr_stock_id][3] = curr_val_mae   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity threshold =  0.9\n",
      "Training model for stock ID 0\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 10s 10s/step - loss: 4.4840 - mae: 4.4840 - val_loss: 3.9241 - val_mae: 3.9241 - lr: 1.0000\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 8s 8s/step - loss: 5.0634 - mae: 5.0634 - val_loss: 3.4561 - val_mae: 3.4561 - lr: 0.9826\n",
      "Epoch 3/20\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#threshold_list = [0.95, 0.9, 0.8, 0.7] \n",
    "threshold_list = [0.90]\n",
    "\n",
    "for threshold in threshold_list:\n",
    "\n",
    "    print('Cosine similarity threshold = ', threshold)\n",
    "    train_models(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The MAEs of the models are: -')\n",
    "count1 = 0\n",
    "count2 = 0\n",
    "for curr_stock_id in models_dict.keys():\n",
    "    print(f'Stock ID = {curr_stock_id}, Cosine similarity threshold = {models_dict[curr_stock_id][1]}, Training MAE = {models_dict[curr_stock_id][2]}, Validation MAE = {models_dict[curr_stock_id][3]}')\n",
    "\n",
    "    #Check the number of stocks predictions for which have an MAE of less than 5.\n",
    "    if models_dict[curr_stock_id][3] < 4:\n",
    "        count1 += 1\n",
    "\n",
    "    if models_dict[curr_stock_id][3] < 5:\n",
    "        count2 += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of stocks predictions for which have an MAE of less than 4 = ', count1)\n",
    "print('Number of stocks predictions for which have an MAE of less than 5 = ', count2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 7056235,
     "sourceId": 57891,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30627,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6253.780111,
   "end_time": "2023-12-09T14:44:23.773902",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-09T13:00:09.993791",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
