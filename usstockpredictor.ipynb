{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Agenda</b>\n",
    "1) Using pipelines\n",
    "<br>\n",
    "2) Construct plots\n",
    "<br>\n",
    "3) Improve performance\n",
    "<br>\n",
    "4) Push code into Github\n",
    "<br>\n",
    "<br>\n",
    "<b>Long-term goals</b>\n",
    "1) Loading data in batches\n",
    "<br>\n",
    "2) Parallel processing (perhaps using Apache Spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "papermill": {
     "duration": 12.871623,
     "end_time": "2023-12-09T13:00:25.746400",
     "exception": false,
     "start_time": "2023-12-09T13:00:12.874777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "papermill": {
     "duration": 14.270179,
     "end_time": "2023-12-09T13:00:40.021887",
     "exception": false,
     "start_time": "2023-12-09T13:00:25.751708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.004764,
     "end_time": "2023-12-09T13:00:40.032300",
     "exception": false,
     "start_time": "2023-12-09T13:00:40.027536",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1) View summary of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "papermill": {
     "duration": 0.012881,
     "end_time": "2023-12-09T13:00:40.050140",
     "exception": false,
     "start_time": "2023-12-09T13:00:40.037259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training data =  (5237980, 17)\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape of the training data = ', dataset_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "papermill": {
     "duration": 0.037969,
     "end_time": "2023-12-09T13:00:40.093386",
     "exception": false,
     "start_time": "2023-12-09T13:00:40.055417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows: -\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>date_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>imbalance_size</th>\n",
       "      <th>imbalance_buy_sell_flag</th>\n",
       "      <th>reference_price</th>\n",
       "      <th>matched_size</th>\n",
       "      <th>far_price</th>\n",
       "      <th>near_price</th>\n",
       "      <th>bid_price</th>\n",
       "      <th>bid_size</th>\n",
       "      <th>ask_price</th>\n",
       "      <th>ask_size</th>\n",
       "      <th>wap</th>\n",
       "      <th>target</th>\n",
       "      <th>time_id</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3180602.69</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>13380276.64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>60651.50</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>8493.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.029704</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166603.91</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>1642214.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>3233.04</td>\n",
       "      <td>1.000660</td>\n",
       "      <td>20605.09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.519986</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>302879.87</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999561</td>\n",
       "      <td>1819368.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>37956.00</td>\n",
       "      <td>1.000298</td>\n",
       "      <td>18995.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-8.389950</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11917682.27</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000171</td>\n",
       "      <td>18389745.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>2324.90</td>\n",
       "      <td>1.000214</td>\n",
       "      <td>479032.40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.010200</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>447549.96</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999532</td>\n",
       "      <td>17860614.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999394</td>\n",
       "      <td>16485.54</td>\n",
       "      <td>1.000016</td>\n",
       "      <td>434.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-7.349849</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stock_id  date_id  seconds_in_bucket  imbalance_size  \\\n",
       "0         0        0                  0      3180602.69   \n",
       "1         1        0                  0       166603.91   \n",
       "2         2        0                  0       302879.87   \n",
       "3         3        0                  0     11917682.27   \n",
       "4         4        0                  0       447549.96   \n",
       "\n",
       "   imbalance_buy_sell_flag  reference_price  matched_size  far_price  \\\n",
       "0                        1         0.999812   13380276.64        NaN   \n",
       "1                       -1         0.999896    1642214.25        NaN   \n",
       "2                       -1         0.999561    1819368.03        NaN   \n",
       "3                       -1         1.000171   18389745.62        NaN   \n",
       "4                       -1         0.999532   17860614.95        NaN   \n",
       "\n",
       "   near_price  bid_price  bid_size  ask_price   ask_size  wap    target  \\\n",
       "0         NaN   0.999812  60651.50   1.000026    8493.03  1.0 -3.029704   \n",
       "1         NaN   0.999896   3233.04   1.000660   20605.09  1.0 -5.519986   \n",
       "2         NaN   0.999403  37956.00   1.000298   18995.00  1.0 -8.389950   \n",
       "3         NaN   0.999999   2324.90   1.000214  479032.40  1.0 -4.010200   \n",
       "4         NaN   0.999394  16485.54   1.000016     434.10  1.0 -7.349849   \n",
       "\n",
       "   time_id row_id  \n",
       "0        0  0_0_0  \n",
       "1        0  0_0_1  \n",
       "2        0  0_0_2  \n",
       "3        0  0_0_3  \n",
       "4        0  0_0_4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('First 5 rows: -')\n",
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "papermill": {
     "duration": 2.651275,
     "end_time": "2023-12-09T13:00:42.750543",
     "exception": false,
     "start_time": "2023-12-09T13:00:40.099268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description of the data: -\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>date_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>imbalance_size</th>\n",
       "      <th>imbalance_buy_sell_flag</th>\n",
       "      <th>reference_price</th>\n",
       "      <th>matched_size</th>\n",
       "      <th>far_price</th>\n",
       "      <th>near_price</th>\n",
       "      <th>bid_price</th>\n",
       "      <th>bid_size</th>\n",
       "      <th>ask_price</th>\n",
       "      <th>ask_size</th>\n",
       "      <th>wap</th>\n",
       "      <th>target</th>\n",
       "      <th>time_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.237980e+06</td>\n",
       "      <td>5.237980e+06</td>\n",
       "      <td>5.237980e+06</td>\n",
       "      <td>5.237760e+06</td>\n",
       "      <td>5.237980e+06</td>\n",
       "      <td>5.237760e+06</td>\n",
       "      <td>5.237760e+06</td>\n",
       "      <td>2.343638e+06</td>\n",
       "      <td>2.380800e+06</td>\n",
       "      <td>5.237760e+06</td>\n",
       "      <td>5.237980e+06</td>\n",
       "      <td>5.237760e+06</td>\n",
       "      <td>5.237980e+06</td>\n",
       "      <td>5.237760e+06</td>\n",
       "      <td>5.237892e+06</td>\n",
       "      <td>5.237980e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.928856e+01</td>\n",
       "      <td>2.415100e+02</td>\n",
       "      <td>2.700000e+02</td>\n",
       "      <td>5.715293e+06</td>\n",
       "      <td>-1.189619e-02</td>\n",
       "      <td>9.999955e-01</td>\n",
       "      <td>4.510025e+07</td>\n",
       "      <td>1.001713e+00</td>\n",
       "      <td>9.996601e-01</td>\n",
       "      <td>9.997263e-01</td>\n",
       "      <td>5.181359e+04</td>\n",
       "      <td>1.000264e+00</td>\n",
       "      <td>5.357568e+04</td>\n",
       "      <td>9.999920e-01</td>\n",
       "      <td>-4.756125e-02</td>\n",
       "      <td>1.331005e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.787176e+01</td>\n",
       "      <td>1.385319e+02</td>\n",
       "      <td>1.587451e+02</td>\n",
       "      <td>2.051591e+07</td>\n",
       "      <td>8.853374e-01</td>\n",
       "      <td>2.532497e-03</td>\n",
       "      <td>1.398413e+08</td>\n",
       "      <td>7.214705e-01</td>\n",
       "      <td>1.216920e-02</td>\n",
       "      <td>2.499345e-03</td>\n",
       "      <td>1.114214e+05</td>\n",
       "      <td>2.510042e-03</td>\n",
       "      <td>1.293554e+05</td>\n",
       "      <td>2.497509e-03</td>\n",
       "      <td>9.452860e+00</td>\n",
       "      <td>7.619271e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>9.352850e-01</td>\n",
       "      <td>4.316610e+03</td>\n",
       "      <td>7.700000e-05</td>\n",
       "      <td>7.869880e-01</td>\n",
       "      <td>9.349150e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.398270e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.380080e-01</td>\n",
       "      <td>-3.852898e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.900000e+01</td>\n",
       "      <td>1.220000e+02</td>\n",
       "      <td>1.300000e+02</td>\n",
       "      <td>8.453415e+04</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>9.987630e-01</td>\n",
       "      <td>5.279575e+06</td>\n",
       "      <td>9.963320e-01</td>\n",
       "      <td>9.971000e-01</td>\n",
       "      <td>9.985290e-01</td>\n",
       "      <td>7.374720e+03</td>\n",
       "      <td>9.990290e-01</td>\n",
       "      <td>7.823700e+03</td>\n",
       "      <td>9.987810e-01</td>\n",
       "      <td>-4.559755e+00</td>\n",
       "      <td>6.729000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.900000e+01</td>\n",
       "      <td>2.420000e+02</td>\n",
       "      <td>2.700000e+02</td>\n",
       "      <td>1.113604e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.999670e-01</td>\n",
       "      <td>1.288264e+07</td>\n",
       "      <td>9.998830e-01</td>\n",
       "      <td>9.998890e-01</td>\n",
       "      <td>9.997280e-01</td>\n",
       "      <td>2.196900e+04</td>\n",
       "      <td>1.000207e+00</td>\n",
       "      <td>2.301792e+04</td>\n",
       "      <td>9.999970e-01</td>\n",
       "      <td>-6.020069e-02</td>\n",
       "      <td>1.334500e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.490000e+02</td>\n",
       "      <td>3.610000e+02</td>\n",
       "      <td>4.100000e+02</td>\n",
       "      <td>4.190951e+06</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.001174e+00</td>\n",
       "      <td>3.270013e+07</td>\n",
       "      <td>1.003318e+00</td>\n",
       "      <td>1.002590e+00</td>\n",
       "      <td>1.000905e+00</td>\n",
       "      <td>5.583168e+04</td>\n",
       "      <td>1.001414e+00</td>\n",
       "      <td>5.787841e+04</td>\n",
       "      <td>1.001149e+00</td>\n",
       "      <td>4.409552e+00</td>\n",
       "      <td>1.990700e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.990000e+02</td>\n",
       "      <td>4.800000e+02</td>\n",
       "      <td>5.400000e+02</td>\n",
       "      <td>2.982028e+09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.077488e+00</td>\n",
       "      <td>7.713682e+09</td>\n",
       "      <td>4.379531e+02</td>\n",
       "      <td>1.309732e+00</td>\n",
       "      <td>1.077488e+00</td>\n",
       "      <td>3.028784e+07</td>\n",
       "      <td>1.077836e+00</td>\n",
       "      <td>5.440500e+07</td>\n",
       "      <td>1.077675e+00</td>\n",
       "      <td>4.460704e+02</td>\n",
       "      <td>2.645400e+04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           stock_id       date_id  seconds_in_bucket  imbalance_size  \\\n",
       "count  5.237980e+06  5.237980e+06       5.237980e+06    5.237760e+06   \n",
       "mean   9.928856e+01  2.415100e+02       2.700000e+02    5.715293e+06   \n",
       "std    5.787176e+01  1.385319e+02       1.587451e+02    2.051591e+07   \n",
       "min    0.000000e+00  0.000000e+00       0.000000e+00    0.000000e+00   \n",
       "25%    4.900000e+01  1.220000e+02       1.300000e+02    8.453415e+04   \n",
       "50%    9.900000e+01  2.420000e+02       2.700000e+02    1.113604e+06   \n",
       "75%    1.490000e+02  3.610000e+02       4.100000e+02    4.190951e+06   \n",
       "max    1.990000e+02  4.800000e+02       5.400000e+02    2.982028e+09   \n",
       "\n",
       "       imbalance_buy_sell_flag  reference_price  matched_size     far_price  \\\n",
       "count             5.237980e+06     5.237760e+06  5.237760e+06  2.343638e+06   \n",
       "mean             -1.189619e-02     9.999955e-01  4.510025e+07  1.001713e+00   \n",
       "std               8.853374e-01     2.532497e-03  1.398413e+08  7.214705e-01   \n",
       "min              -1.000000e+00     9.352850e-01  4.316610e+03  7.700000e-05   \n",
       "25%              -1.000000e+00     9.987630e-01  5.279575e+06  9.963320e-01   \n",
       "50%               0.000000e+00     9.999670e-01  1.288264e+07  9.998830e-01   \n",
       "75%               1.000000e+00     1.001174e+00  3.270013e+07  1.003318e+00   \n",
       "max               1.000000e+00     1.077488e+00  7.713682e+09  4.379531e+02   \n",
       "\n",
       "         near_price     bid_price      bid_size     ask_price      ask_size  \\\n",
       "count  2.380800e+06  5.237760e+06  5.237980e+06  5.237760e+06  5.237980e+06   \n",
       "mean   9.996601e-01  9.997263e-01  5.181359e+04  1.000264e+00  5.357568e+04   \n",
       "std    1.216920e-02  2.499345e-03  1.114214e+05  2.510042e-03  1.293554e+05   \n",
       "min    7.869880e-01  9.349150e-01  0.000000e+00  9.398270e-01  0.000000e+00   \n",
       "25%    9.971000e-01  9.985290e-01  7.374720e+03  9.990290e-01  7.823700e+03   \n",
       "50%    9.998890e-01  9.997280e-01  2.196900e+04  1.000207e+00  2.301792e+04   \n",
       "75%    1.002590e+00  1.000905e+00  5.583168e+04  1.001414e+00  5.787841e+04   \n",
       "max    1.309732e+00  1.077488e+00  3.028784e+07  1.077836e+00  5.440500e+07   \n",
       "\n",
       "                wap        target       time_id  \n",
       "count  5.237760e+06  5.237892e+06  5.237980e+06  \n",
       "mean   9.999920e-01 -4.756125e-02  1.331005e+04  \n",
       "std    2.497509e-03  9.452860e+00  7.619271e+03  \n",
       "min    9.380080e-01 -3.852898e+02  0.000000e+00  \n",
       "25%    9.987810e-01 -4.559755e+00  6.729000e+03  \n",
       "50%    9.999970e-01 -6.020069e-02  1.334500e+04  \n",
       "75%    1.001149e+00  4.409552e+00  1.990700e+04  \n",
       "max    1.077675e+00  4.460704e+02  2.645400e+04  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Description of the data: -')\n",
    "dataset_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.005217,
     "end_time": "2023-12-09T13:00:42.761610",
     "exception": false,
     "start_time": "2023-12-09T13:00:42.756393",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2) Handling missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.00515,
     "end_time": "2023-12-09T13:00:42.772122",
     "exception": false,
     "start_time": "2023-12-09T13:00:42.766972",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.1) Determine missingness in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "papermill": {
     "duration": 0.230836,
     "end_time": "2023-12-09T13:00:43.009255",
     "exception": false,
     "start_time": "2023-12-09T13:00:42.778419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of missing values for various columns of the dataframe: -\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "stock_id                    0.000000\n",
       "date_id                     0.000000\n",
       "seconds_in_bucket           0.000000\n",
       "imbalance_size              0.004200\n",
       "imbalance_buy_sell_flag     0.000000\n",
       "reference_price             0.004200\n",
       "matched_size                0.004200\n",
       "far_price                  55.256836\n",
       "near_price                 54.547364\n",
       "bid_price                   0.004200\n",
       "bid_size                    0.000000\n",
       "ask_price                   0.004200\n",
       "ask_size                    0.000000\n",
       "wap                         0.004200\n",
       "target                      0.001680\n",
       "time_id                     0.000000\n",
       "row_id                      0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"List of missing values for various columns of the dataframe: -\")\n",
    "num_missing_vals_series = (dataset_df.isnull().sum(axis = 0)/dataset_df.shape[0]) * 100\n",
    "num_missing_vals_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "papermill": {
     "duration": 1.306441,
     "end_time": "2023-12-09T13:00:44.321862",
     "exception": false,
     "start_time": "2023-12-09T13:00:43.015421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature = imbalance_size\n",
      "Percentage of missing values = 0.004200092402032845\n",
      "Dropping missing values for imbalance_size\n",
      "\n",
      "\n",
      "Feature = reference_price\n",
      "Percentage of missing values = 0.004200092402032845\n",
      "Dropping missing values for reference_price\n",
      "\n",
      "\n",
      "Feature = matched_size\n",
      "Percentage of missing values = 0.004200092402032845\n",
      "Dropping missing values for matched_size\n",
      "\n",
      "\n",
      "Feature = bid_price\n",
      "Percentage of missing values = 0.004200092402032845\n",
      "Dropping missing values for bid_price\n",
      "\n",
      "\n",
      "Feature = ask_price\n",
      "Percentage of missing values = 0.004200092402032845\n",
      "Dropping missing values for ask_price\n",
      "\n",
      "\n",
      "Feature = wap\n",
      "Percentage of missing values = 0.004200092402032845\n",
      "Dropping missing values for wap\n",
      "\n",
      "\n",
      "Feature = target\n",
      "Percentage of missing values = 0.0016800369608131378\n",
      "Dropping missing values for target\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "\n",
    "for feature in num_missing_vals_series.index:\n",
    "    \n",
    "    if (num_missing_vals_series[feature] > 0) and (num_missing_vals_series[feature] < 1):\n",
    "        print(f'Feature = {feature}')\n",
    "        print(f'Percentage of missing values = {num_missing_vals_series[feature]}')\n",
    "        print(f'Dropping missing values for {feature}')\n",
    "        dataset_df.dropna(subset = feature, inplace = True)\n",
    "        print('\\n')\n",
    "    \n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "papermill": {
     "duration": 0.225137,
     "end_time": "2023-12-09T13:00:44.553295",
     "exception": false,
     "start_time": "2023-12-09T13:00:44.328158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stock_id                    0.000000\n",
       "date_id                     0.000000\n",
       "seconds_in_bucket           0.000000\n",
       "imbalance_size              0.000000\n",
       "imbalance_buy_sell_flag     0.000000\n",
       "reference_price             0.000000\n",
       "matched_size                0.000000\n",
       "far_price                  55.254956\n",
       "near_price                 54.545455\n",
       "bid_price                   0.000000\n",
       "bid_size                    0.000000\n",
       "ask_price                   0.000000\n",
       "ask_size                    0.000000\n",
       "wap                         0.000000\n",
       "target                      0.000000\n",
       "time_id                     0.000000\n",
       "row_id                      0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_missing_vals_series = (dataset_df.isnull().sum(axis = 0)/dataset_df.shape[0]) * 100\n",
    "num_missing_vals_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "papermill": {
     "duration": 0.683563,
     "end_time": "2023-12-09T13:00:45.243047",
     "exception": false,
     "start_time": "2023-12-09T13:00:44.559484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_df.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "papermill": {
     "duration": 0.228316,
     "end_time": "2023-12-09T13:00:45.478875",
     "exception": false,
     "start_time": "2023-12-09T13:00:45.250559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stock_id                   0.0\n",
       "date_id                    0.0\n",
       "seconds_in_bucket          0.0\n",
       "imbalance_size             0.0\n",
       "imbalance_buy_sell_flag    0.0\n",
       "reference_price            0.0\n",
       "matched_size               0.0\n",
       "far_price                  0.0\n",
       "near_price                 0.0\n",
       "bid_price                  0.0\n",
       "bid_size                   0.0\n",
       "ask_price                  0.0\n",
       "ask_size                   0.0\n",
       "wap                        0.0\n",
       "target                     0.0\n",
       "time_id                    0.0\n",
       "row_id                     0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_missing_vals_series = (dataset_df.isnull().sum(axis = 0)/dataset_df.shape[0]) * 100\n",
    "num_missing_vals_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.005862,
     "end_time": "2023-12-09T13:00:45.491222",
     "exception": false,
     "start_time": "2023-12-09T13:00:45.485360",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3) Reshaping and preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_reshaped_df = dataset_df\n",
    "dataset_reshaped_df.sort_values(by = ['stock_id', 'date_id', 'seconds_in_bucket'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_features(df):\n",
    "    \n",
    "    df['imbalance_size'] = df['imbalance_size'] * df['imbalance_buy_sell_flag']\n",
    "\n",
    "def compute_rollover_features(df):\n",
    "    \n",
    "    df['prev_target'] = df.groupby('stock_id')['target'].shift(1)\n",
    "    df.fillna(0, inplace = True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def standardize_features(df, mu_dict=None, sigma_dict=None):\n",
    "    \n",
    "    if (mu_dict is None) and (sigma_dict is None):\n",
    "        \n",
    "        mu_dict = {}\n",
    "        sigma_dict = {}\n",
    "        \n",
    "        mu_dict['imbalance_size'] = [0]*200\n",
    "        mu_dict['reference_price'] = [0]*200\n",
    "        mu_dict['matched_size'] = [0]*200\n",
    "        mu_dict['far_price'] = [0]*200\n",
    "        mu_dict['near_price'] = [0]*200\n",
    "        mu_dict['bid_price'] = [0]*200\n",
    "        mu_dict['bid_size'] = [0]*200\n",
    "        mu_dict['ask_price'] = [0]*200\n",
    "        mu_dict['ask_size'] = [0]*200\n",
    "        mu_dict['wap'] = [0]*200\n",
    "        mu_dict['prev_target'] = [0]*200\n",
    "        \n",
    "        sigma_dict['imbalance_size'] = [0]*200\n",
    "        sigma_dict['reference_price'] = [0]*200\n",
    "        sigma_dict['matched_size'] = [0]*200\n",
    "        sigma_dict['far_price'] = [0]*200\n",
    "        sigma_dict['near_price'] = [0]*200\n",
    "        sigma_dict['bid_price'] = [0]*200\n",
    "        sigma_dict['bid_size'] = [0]*200\n",
    "        sigma_dict['ask_price'] = [0]*200\n",
    "        sigma_dict['ask_size'] = [0]*200\n",
    "        sigma_dict['wap'] = [0]*200\n",
    "        sigma_dict['prev_target'] = [0]*200\n",
    "        \n",
    "        for stock_id in range(df['stock_id'].max()+1):\n",
    "            \n",
    "            mu_dict['imbalance_size'][stock_id] = df[df['stock_id'] == stock_id]['imbalance_size'].mean()\n",
    "            mu_dict['reference_price'][stock_id] = df[df['stock_id'] == stock_id]['reference_price'].mean()\n",
    "            mu_dict['matched_size'][stock_id] = df[df['stock_id'] == stock_id]['matched_size'].mean()\n",
    "            mu_dict['far_price'][stock_id] = df[df['stock_id'] == stock_id]['far_price'].mean()\n",
    "            mu_dict['near_price'][stock_id] = df[df['stock_id'] == stock_id]['near_price'].mean()\n",
    "            mu_dict['bid_price'][stock_id] = df[df['stock_id'] == stock_id]['bid_price'].mean()\n",
    "            mu_dict['bid_size'][stock_id] = df[df['stock_id'] == stock_id]['bid_size'].mean()\n",
    "            mu_dict['ask_price'][stock_id] = df[df['stock_id'] == stock_id]['ask_price'].mean()\n",
    "            mu_dict['ask_size'][stock_id] = df[df['stock_id'] == stock_id]['ask_size'].mean()\n",
    "            mu_dict['wap'][stock_id] = df[df['stock_id'] == stock_id]['wap'].mean()\n",
    "            mu_dict['prev_target'][stock_id] = df[df['stock_id'] == stock_id]['prev_target'].mean()\n",
    "            \n",
    "            sigma_dict['imbalance_size'][stock_id] = df[df['stock_id'] == stock_id]['imbalance_size'].std()\n",
    "            sigma_dict['reference_price'][stock_id] = df[df['stock_id'] == stock_id]['reference_price'].std()\n",
    "            sigma_dict['matched_size'][stock_id] = df[df['stock_id'] == stock_id]['matched_size'].std()\n",
    "            sigma_dict['far_price'][stock_id] = df[df['stock_id'] == stock_id]['far_price'].std()\n",
    "            sigma_dict['near_price'][stock_id] = df[df['stock_id'] == stock_id]['near_price'].std()\n",
    "            sigma_dict['bid_price'][stock_id] = df[df['stock_id'] == stock_id]['bid_price'].std()\n",
    "            sigma_dict['bid_size'][stock_id] = df[df['stock_id'] == stock_id]['bid_size'].std()\n",
    "            sigma_dict['ask_price'][stock_id] = df[df['stock_id'] == stock_id]['ask_price'].std()\n",
    "            sigma_dict['ask_size'][stock_id] = df[df['stock_id'] == stock_id]['ask_size'].std()\n",
    "            sigma_dict['wap'][stock_id] = df[df['stock_id'] == stock_id]['wap'].std()\n",
    "            sigma_dict['prev_target'][stock_id] = df[df['stock_id'] == stock_id]['prev_target'].std()\n",
    "    \n",
    "    df['imbalance_size'] = (df['imbalance_size'] - df['stock_id'].map(lambda x: mu_dict['imbalance_size'][x]))/df['stock_id'].map(lambda x: sigma_dict['imbalance_size'][x])\n",
    "    df['reference_price'] = (df['reference_price'] - df['stock_id'].map(lambda x: mu_dict['reference_price'][x]))/df['stock_id'].map(lambda x: sigma_dict['reference_price'][x])\n",
    "    df['matched_size'] = (df['matched_size'] - df['stock_id'].map(lambda x: mu_dict['matched_size'][x]))/df['stock_id'].map(lambda x: sigma_dict['matched_size'][x])\n",
    "    df['far_price'] = (df['far_price'] - df['stock_id'].map(lambda x: mu_dict['far_price'][x]))/df['stock_id'].map(lambda x: sigma_dict['far_price'][x])\n",
    "    df['near_price'] = (df['near_price'] - df['stock_id'].map(lambda x: mu_dict['near_price'][x]))/df['stock_id'].map(lambda x: sigma_dict['near_price'][x])\n",
    "    df['bid_price'] = (df['bid_price'] - df['stock_id'].map(lambda x: mu_dict['bid_price'][x]))/df['stock_id'].map(lambda x: sigma_dict['bid_price'][x])\n",
    "    df['bid_size'] = (df['bid_size'] - df['stock_id'].map(lambda x: mu_dict['bid_size'][x]))/df['stock_id'].map(lambda x: sigma_dict['bid_size'][x])\n",
    "    df['ask_price'] = (df['ask_price'] - df['stock_id'].map(lambda x: mu_dict['ask_price'][x]))/df['stock_id'].map(lambda x: sigma_dict['ask_price'][x])\n",
    "    df['ask_size'] = (df['ask_size'] - df['stock_id'].map(lambda x: mu_dict['ask_size'][x]))/df['stock_id'].map(lambda x: sigma_dict['ask_size'][x])    \n",
    "    df['wap'] = (df['wap'] - df['stock_id'].map(lambda x: mu_dict['wap'][x]))/df['stock_id'].map(lambda x: sigma_dict['wap'][x])        \n",
    "        \n",
    "    df['prev_target'] = (df['prev_target'] - df['stock_id'].map(lambda x: mu_dict['prev_target'][x]))/df['stock_id'].map(lambda x: sigma_dict['prev_target'][x])\n",
    "    \n",
    "    return (mu_dict, sigma_dict)\n",
    "   \n",
    "def drop_features(df):\n",
    "    \n",
    "    #Drop the following features.\n",
    "    df.drop(['row_id', 'imbalance_buy_sell_flag'], axis = 1, inplace = True)\n",
    "    \n",
    "    if 'currently_scored' in df.columns:\n",
    "        df.drop(['currently_scored'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recompute some features.\n",
    "compute_features(dataset_reshaped_df)\n",
    "\n",
    "#Compute roll-over features.\n",
    "dataset_reshaped_df = compute_rollover_features(dataset_reshaped_df)\n",
    "\n",
    "#Standardize features.\n",
    "mu_dict, sigma_dict = standardize_features(dataset_reshaped_df)\n",
    "\n",
    "#Drop features from the dataset.\n",
    "drop_features(dataset_reshaped_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>date_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>imbalance_size</th>\n",
       "      <th>reference_price</th>\n",
       "      <th>matched_size</th>\n",
       "      <th>far_price</th>\n",
       "      <th>near_price</th>\n",
       "      <th>bid_price</th>\n",
       "      <th>bid_size</th>\n",
       "      <th>ask_price</th>\n",
       "      <th>ask_size</th>\n",
       "      <th>wap</th>\n",
       "      <th>target</th>\n",
       "      <th>time_id</th>\n",
       "      <th>prev_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.420313</td>\n",
       "      <td>-0.013518</td>\n",
       "      <td>-0.587909</td>\n",
       "      <td>-0.906572</td>\n",
       "      <td>-0.912704</td>\n",
       "      <td>0.045702</td>\n",
       "      <td>0.326687</td>\n",
       "      <td>0.042624</td>\n",
       "      <td>-0.517844</td>\n",
       "      <td>0.094030</td>\n",
       "      <td>-3.029704</td>\n",
       "      <td>0</td>\n",
       "      <td>0.043116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.218021</td>\n",
       "      <td>0.113973</td>\n",
       "      <td>-0.498553</td>\n",
       "      <td>-0.906572</td>\n",
       "      <td>-0.912704</td>\n",
       "      <td>0.045702</td>\n",
       "      <td>-0.292750</td>\n",
       "      <td>0.042624</td>\n",
       "      <td>-0.257284</td>\n",
       "      <td>0.029652</td>\n",
       "      <td>0.389814</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.457311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.218021</td>\n",
       "      <td>0.050228</td>\n",
       "      <td>-0.498553</td>\n",
       "      <td>-0.906572</td>\n",
       "      <td>-0.912704</td>\n",
       "      <td>0.045702</td>\n",
       "      <td>-0.416637</td>\n",
       "      <td>-0.021117</td>\n",
       "      <td>-0.454750</td>\n",
       "      <td>-0.000153</td>\n",
       "      <td>4.220009</td>\n",
       "      <td>2</td>\n",
       "      <td>0.107503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0.218021</td>\n",
       "      <td>0.177718</td>\n",
       "      <td>-0.498553</td>\n",
       "      <td>-0.906572</td>\n",
       "      <td>-0.912704</td>\n",
       "      <td>0.173495</td>\n",
       "      <td>0.264903</td>\n",
       "      <td>0.106365</td>\n",
       "      <td>0.136070</td>\n",
       "      <td>0.144697</td>\n",
       "      <td>5.450249</td>\n",
       "      <td>3</td>\n",
       "      <td>0.740151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.209248</td>\n",
       "      <td>0.369550</td>\n",
       "      <td>-0.494678</td>\n",
       "      <td>-0.906572</td>\n",
       "      <td>-0.912704</td>\n",
       "      <td>0.301885</td>\n",
       "      <td>-0.283994</td>\n",
       "      <td>0.298183</td>\n",
       "      <td>-0.203679</td>\n",
       "      <td>0.282991</td>\n",
       "      <td>3.169775</td>\n",
       "      <td>4</td>\n",
       "      <td>0.943354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     stock_id  date_id  seconds_in_bucket  imbalance_size  reference_price  \\\n",
       "0           0        0                  0        0.420313        -0.013518   \n",
       "191         0        0                 10        0.218021         0.113973   \n",
       "382         0        0                 20        0.218021         0.050228   \n",
       "573         0        0                 30        0.218021         0.177718   \n",
       "764         0        0                 40        0.209248         0.369550   \n",
       "\n",
       "     matched_size  far_price  near_price  bid_price  bid_size  ask_price  \\\n",
       "0       -0.587909  -0.906572   -0.912704   0.045702  0.326687   0.042624   \n",
       "191     -0.498553  -0.906572   -0.912704   0.045702 -0.292750   0.042624   \n",
       "382     -0.498553  -0.906572   -0.912704   0.045702 -0.416637  -0.021117   \n",
       "573     -0.498553  -0.906572   -0.912704   0.173495  0.264903   0.106365   \n",
       "764     -0.494678  -0.906572   -0.912704   0.301885 -0.283994   0.298183   \n",
       "\n",
       "     ask_size       wap    target  time_id  prev_target  \n",
       "0   -0.517844  0.094030 -3.029704        0     0.043116  \n",
       "191 -0.257284  0.029652  0.389814        1    -0.457311  \n",
       "382 -0.454750 -0.000153  4.220009        2     0.107503  \n",
       "573  0.136070  0.144697  5.450249        3     0.740151  \n",
       "764 -0.203679  0.282991  3.169775        4     0.943354  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_reshaped_df[dataset_reshaped_df['stock_id'] == 0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = dataset_reshaped_df[dataset_reshaped_df['date_id'] < 478]\n",
    "val_df = dataset_reshaped_df[dataset_reshaped_df['date_id'] >= 478]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 7746, 16)\n"
     ]
    }
   ],
   "source": [
    "def get_similar_training_data(stock_id, test_val_data_dates, threshold = 0.9):\n",
    "    \n",
    "    #Get all training data associated with the stock_id.\n",
    "    stock_train_df = train_df[train_df['stock_id'] == stock_id].copy()\n",
    "    \n",
    "    #Drop columns not relevant for the cosine similarity and convert the result to arrays.\n",
    "    train_curr_date_array = stock_train_df.drop(['stock_id', 'target', 'date_id', 'time_id', 'seconds_in_bucket'], axis = 1).values\n",
    "    train_target_date_array = (stock_train_df['target'].values).reshape(-1, 1)\n",
    "    \n",
    "    indices_of_closest_arrays = None\n",
    "    \n",
    "    for test_val_data_date in test_val_data_dates:\n",
    "        \n",
    "        #Compute the cosine similarity between the single row of test data and the all the rows of training data.\n",
    "        cos_sim = cosine_similarity(train_curr_date_array, test_val_data_date.reshape(1, -1))\n",
    "        \n",
    "        if indices_of_closest_arrays is None:\n",
    "            #Determine the indices of training data with higher cosine similarity than the threshold.\n",
    "            indices_of_closest_arrays = np.where(cos_sim > threshold)[0]\n",
    "        \n",
    "        else:\n",
    "            indices_of_closest_arrays = np.concatenate((indices_of_closest_arrays, np.where(cos_sim > threshold)[0]))\n",
    "    \n",
    "    indices_of_closest_arrays = np.unique(indices_of_closest_arrays)\n",
    "    indices_of_closest_arrays = np.sort(indices_of_closest_arrays)\n",
    "    \n",
    "    #Get training rows corressponding to the indices determined earlier.\n",
    "    ret_train_arr = stock_train_df.iloc[indices_of_closest_arrays].values\n",
    "    ret_train_arr = ret_train_arr.reshape(1, ret_train_arr.shape[0], ret_train_arr.shape[1])\n",
    "    \n",
    "    return ret_train_arr\n",
    "\n",
    "#& (val_df['seconds_in_bucket'] == 0)\n",
    "tr_array = get_similar_training_data(2, val_df[(val_df['stock_id'] == 2) & (val_df['date_id'] == 478)].drop(['stock_id', 'target', 'date_id', 'time_id', 'seconds_in_bucket', 'target'], axis = 1).values, threshold = 0.9)\n",
    "print(tr_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(165, 15) (165, 15)\n"
     ]
    }
   ],
   "source": [
    "def get_valid_test_data(stock_id):\n",
    "    \n",
    "    test_val_df = val_df[val_df['stock_id'] == stock_id].copy()\n",
    "    #test_val_df.drop(['stock_id', 'date_id', 'time_id', 'seconds_in_bucket'], inplace = True, axis = 1)\n",
    "    \n",
    "    val_target_array = None\n",
    "    \n",
    "    if 'target' in test_val_df.columns:\n",
    "        val_target_array = (test_val_df['target'].values).reshape(-1, 1)\n",
    "        test_val_df.drop(['target'], inplace = True, axis = 1)\n",
    "    \n",
    "    val_array = test_val_df.values\n",
    "    val_target_array = val_target_array\n",
    "    \n",
    "    return val_array, val_target_array\n",
    "\n",
    "tr_array = get_valid_test_data(0)\n",
    "print(tr_array[0].shape, tr_array[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.006254,
     "end_time": "2023-12-09T13:00:48.204085",
     "exception": false,
     "start_time": "2023-12-09T13:00:48.197831",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4) Creating models specific to each stock ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "papermill": {
     "duration": 0.015892,
     "end_time": "2023-12-09T13:00:48.226079",
     "exception": false,
     "start_time": "2023-12-09T13:00:48.210187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Function declarations\n",
    "def step_decay(epoch, learning_rate):\n",
    "    #Initialize the base initial learning rate, drop factor, and epochs to drop every\n",
    "    init_lr = 1\n",
    "    factor = 0.9\n",
    "    drop_every = 6\n",
    "    # compute learning rate for the current epoch\n",
    "    learning_rate = init_lr*(factor ** (np.floor(epoch) / drop_every))\n",
    "    return learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00000000e+00,  4.78000000e+02,  0.00000000e+00,\n",
       "        -3.25478308e-01,  2.40145801e-02, -6.74912495e-01,\n",
       "        -9.06572064e-01, -9.12704449e-01,  8.33233301e-02,\n",
       "        -1.74007138e-01,  5.69211617e-02, -5.05973453e-01,\n",
       "         9.40295844e-02, -5.42998300e+00,  2.62900000e+04,\n",
       "         5.11418658e-03]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df[(val_df['stock_id'] == 0) & (val_df['time_id'] == 26290)].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size = 11\n",
      "Sequence length = 55\n"
     ]
    }
   ],
   "source": [
    "#Input dimension - 1 has been added because 'PREV_TARGET field is introduced much later'\n",
    "INPUT_SIZE = 11\n",
    "print(f'Input size = {INPUT_SIZE}')\n",
    "\n",
    "#Declaring a dictionary of models - a model for each stock ID.\n",
    "models_dict = {}\n",
    "\n",
    "#Sequence length of the model.\n",
    "SEQ_LEN = 55 * 1\n",
    "print(f'Sequence length = {SEQ_LEN}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get sequence of a specific length starting backwards from the records in data_array.\n",
    "def get_sequence(seq_len, curr_stock_id, data_array):\n",
    "        \n",
    "    #Create an empty array of sequences\n",
    "    data_seq_array = np.zeros((data_array.shape[0], seq_len, data_array.shape[1]))\n",
    "    \n",
    "    #Fetch all training data associated with the current stock ID.\n",
    "    stock_train_array = train_df[train_df['stock_id'] == curr_stock_id].values\n",
    "    \n",
    "    #Iterate through the rows of the validation data.\n",
    "    for index, row in enumerate(data_array):\n",
    "        \n",
    "        #print('-', index)\n",
    "        \n",
    "        #print(stock_train_array[:, -2].shape, row[-2])\n",
    "        #print(stock_train_array[:, -2] >= row[-2] - seq_len + 1) & (stock_train_array[:, -2] <= row[-2])\n",
    "        \n",
    "        \n",
    "        #Get the sequence associated with the current row.\n",
    "        cond_mask = (stock_train_array[:, -2] >= row[-2] - seq_len + 1) & (stock_train_array[:, -2] <= row[-2])\n",
    "        \n",
    "        #Get the number of sequence elements found in the training data.\n",
    "        num_seq_elem_train = np.sum(cond_mask)\n",
    "        #print(\"1)\", num_seq_elem_train)\n",
    "        \n",
    "        #Fill up the target array with the rows found in the training data array.\n",
    "        data_seq_array[index][0:num_seq_elem_train] = stock_train_array[cond_mask][0:num_seq_elem_train]\n",
    "        #print(\"2)\", stock_train_array[cond_mask][0:num_seq_elem_train].shape)\n",
    "        \n",
    "        #Fill up the target array with rows found in the validationd data array (not found in training data array)\n",
    "        data_seq_array[index][num_seq_elem_train:] = data_array[0:seq_len-num_seq_elem_train]\n",
    "        #print(\"3)\", data_array[0:seq_len-num_seq_elem_train].shape)\n",
    "    \n",
    "    return data_seq_array\n",
    "        \n",
    "#test_array = get_sequence(SEQ_LEN, 0)\n",
    "#print(test_array.shape)\n",
    "#print(test_array[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><u>Note: -</u></b><br>\n",
    "It was earlier found that the training error in most cases was higher than the validation error.<br>\n",
    "<br>\n",
    "<b><u>Conjecture: -</u></b><br>\n",
    "The training data is selected on the basis of its cosine similarity to the validation data. Therefore, the records comprising the training data are more similar to the validation data than they are to each other. This causes the validation error to be lower than the training error.<br>\n",
    "<br>\n",
    "<b><u>Conclusion: -</u></b><br>\n",
    "Because of the manner of selecting training data, the training error is likely to be higher than the validation error. Therefore, training error does not mean much here. The efficacy of the model will be determined purely based on the validation error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(threshold):\n",
    "    \n",
    "    early_checkpoint = EarlyStopping(patience=2, monitor='mae', mode='min')\n",
    "\n",
    "    seed_value = 42\n",
    "    tf.random.set_seed(seed_value)\n",
    "\n",
    "    #Construct train/validation sets separately for all stock IDs.\n",
    "    for curr_stock_id in dataset_reshaped_df['stock_id'].unique():\n",
    "        \n",
    "        print(f'Training model for stock ID {curr_stock_id}')\n",
    "        \n",
    "        curr_train_mae = 0\n",
    "        curr_val_mae = 0\n",
    "        \n",
    "        val_data_array = val_df[val_df['stock_id'] == curr_stock_id].copy().values\n",
    "        \n",
    "        #Get SEQ_LEN records prior to the validation rows for the current stock ID.\n",
    "        val_seq_array = get_sequence(SEQ_LEN, curr_stock_id, val_data_array)\n",
    "        #print('Validation sequence: - ', val_seq_array.shape)\n",
    "        \n",
    "        #For each sequence, select training records that are similar to the validation records (last element of the \n",
    "        #validation sequence) determined above. The following indices will be removed while determining similarity: -\n",
    "        #'stock_id' - 1\n",
    "        #'date_id' - 2\n",
    "        #'seconds_in_bucket' - 3\n",
    "        #'target' - 14\n",
    "        #'time_id' - 15\n",
    "        excluded_indices = np.array([1,2,3,14,15])\n",
    "        indices_mask = np.ones(val_seq_array.shape[2], dtype = bool)\n",
    "        indices_mask[excluded_indices] = False\n",
    "        curr_train_similar_rows = get_similar_training_data(curr_stock_id, val_seq_array[:, -1, indices_mask], threshold = threshold)\n",
    "        print(curr_train_similar_rows.shape)\n",
    "        if curr_train_similar_rows.shape[1] <= 1000:\n",
    "            curr_train_similar_rows = get_similar_training_data(curr_stock_id, val_seq_array[:, -1, indices_mask], threshold = threshold - 0.10)\n",
    "            if curr_train_similar_rows.shape[1] <= 1000:\n",
    "                curr_train_similar_rows = get_similar_training_data(curr_stock_id, val_seq_array[:, -1, indices_mask], threshold = threshold - 0.20)\n",
    "                if curr_train_similar_rows.shape[1] <= 1000:\n",
    "                    curr_train_similar_rows = get_similar_training_data(curr_stock_id, val_seq_array[:, -1, indices_mask], threshold = threshold - 0.30)\n",
    "                    if curr_train_similar_rows.shape[1] <= 1000:\n",
    "                        curr_train_similar_rows = get_similar_training_data(curr_stock_id, val_seq_array[:, -1, indices_mask], threshold = threshold - 0.40)\n",
    "                        if curr_train_similar_rows.shape[1] <= 1000:\n",
    "                            curr_train_similar_rows = get_similar_training_data(curr_stock_id, val_seq_array[:, -1, indices_mask], threshold = threshold - 0.50)\n",
    "                            print(f\"Threshold = {threshold - 0.50}\")\n",
    "                        else:\n",
    "                            print(f\"Threshold = {threshold - 0.40}\")\n",
    "                    else:\n",
    "                        print(f\"Threshold = {threshold - 0.30}\")\n",
    "                else:\n",
    "                    print(f\"Threshold = {threshold - 0.20}\")\n",
    "            else:\n",
    "                print(f\"Threshold = {threshold - 0.10}\")\n",
    "        else:\n",
    "            print(f\"Threshold = {threshold}\")\n",
    "        \n",
    "        #print(\"Similar training rows' shape: - \", curr_train_similar_rows.shape)\n",
    "        \n",
    "        #Get SEQ_LEN records prior to the training rows for the current stock ID.\n",
    "        train_seq_array = get_sequence(SEQ_LEN, curr_stock_id, curr_train_similar_rows[0])\n",
    "        #print('Training sequence: - ', train_seq_array.shape)\n",
    "        \n",
    "        #Construct a GRU model for the current stock ID.\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.GRU(8, return_sequences=True, input_shape=(SEQ_LEN, INPUT_SIZE)),\n",
    "            tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(1, activation='linear'))])\n",
    "        \n",
    "        #Compile the model.\n",
    "        lr_scheduler = keras.callbacks.LearningRateScheduler(step_decay)\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "        model.compile(loss=\"mean_absolute_error\", optimizer=opt, metrics=[\"mae\"])\n",
    "        \n",
    "        #Create training dataset.\n",
    "        print('Training data set size = ', train_seq_array.shape)\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((train_seq_array[:, :, indices_mask], train_seq_array[:, :, 15]))\n",
    "        train_dataset = train_dataset.batch(50)\n",
    "        \n",
    "        #Create validation dataset.\n",
    "        print('Validation data set size = ', val_seq_array.shape)\n",
    "        val_dataset = tf.data.Dataset.from_tensor_slices((val_seq_array[:, :, indices_mask], val_seq_array[:, :, 15]))\n",
    "        val_dataset = val_dataset.batch(50)\n",
    "        \n",
    "        #Train the model.\n",
    "        history = model.fit(train_dataset, validation_data = val_dataset, epochs=20, callbacks=[early_checkpoint, lr_scheduler], verbose = 0)\n",
    "            \n",
    "        #Determine the cumulative training and validation MAEs across the different rows of the validation\n",
    "        #data.\n",
    "        curr_train_mae = history.history['mae'][-1]\n",
    "        curr_val_mae = history.history['val_mae'][-1]\n",
    "        \n",
    "        print(f'Training MAE = {curr_train_mae}, Validation MAE = {curr_val_mae}')\n",
    "        \n",
    "        if curr_stock_id not in models_dict.keys():\n",
    "            models_dict[curr_stock_id] = [model, threshold, curr_train_mae, curr_val_mae]\n",
    "        \n",
    "        else:\n",
    "            if models_dict[curr_stock_id][3] > curr_val_mae:\n",
    "                models_dict[curr_stock_id][0] = model\n",
    "                models_dict[curr_stock_id][1] = threshold   \n",
    "                models_dict[curr_stock_id][2] = curr_train_mae\n",
    "                models_dict[curr_stock_id][3] = curr_val_mae\n",
    "        \n",
    "        print('------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity threshold =  0.95\n",
      "Training model for stock ID 0\n",
      "(1, 2199, 16)\n",
      "Threshold = 0.95\n",
      "Training data set size =  (2199, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.7623547911643982, Validation MAE = 0.7081812620162964\n",
      "------------------------------\n",
      "Training model for stock ID 1\n",
      "(1, 166, 16)\n",
      "Threshold = 0.85\n",
      "Training data set size =  (1778, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.7468001246452332, Validation MAE = 0.6311120986938477\n",
      "------------------------------\n",
      "Training model for stock ID 2\n",
      "(1, 20, 16)\n",
      "Threshold = 0.75\n",
      "Training data set size =  (4601, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8455199599266052, Validation MAE = 0.8830938339233398\n",
      "------------------------------\n",
      "Training model for stock ID 3\n",
      "(1, 220, 16)\n",
      "Threshold = 0.85\n",
      "Training data set size =  (1427, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.7316550612449646, Validation MAE = 0.5541003346443176\n",
      "------------------------------\n",
      "Training model for stock ID 4\n",
      "(1, 255, 16)\n",
      "Threshold = 0.85\n",
      "Training data set size =  (1025, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.6467030644416809, Validation MAE = 0.5069093704223633\n",
      "------------------------------\n",
      "Training model for stock ID 5\n",
      "(1, 66, 16)\n",
      "Threshold = 0.75\n",
      "Training data set size =  (1669, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.6203770041465759, Validation MAE = 0.38522112369537354\n",
      "------------------------------\n",
      "Training model for stock ID 6\n",
      "(1, 31, 16)\n",
      "Threshold = 0.75\n",
      "Training data set size =  (1638, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.6207630634307861, Validation MAE = 0.6588804125785828\n",
      "------------------------------\n",
      "Training model for stock ID 7\n",
      "(1, 133, 16)\n",
      "Threshold = 0.75\n",
      "Training data set size =  (1424, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.49060478806495667, Validation MAE = 0.38904255628585815\n",
      "------------------------------\n",
      "Training model for stock ID 8\n",
      "(1, 59, 16)\n",
      "Threshold = 0.75\n",
      "Training data set size =  (1081, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.6820960640907288, Validation MAE = 0.5763413906097412\n",
      "------------------------------\n",
      "Training model for stock ID 9\n",
      "(1, 124, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1783, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.7562897801399231, Validation MAE = 0.8097860813140869\n",
      "------------------------------\n",
      "Training model for stock ID 10\n",
      "(1, 39, 16)\n",
      "Threshold = 0.75\n",
      "Training data set size =  (1356, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.6591199636459351, Validation MAE = 0.592311441898346\n",
      "------------------------------\n",
      "Training model for stock ID 11\n",
      "(1, 137, 16)\n",
      "Threshold = 0.75\n",
      "Training data set size =  (1170, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.782374918460846, Validation MAE = 0.3660110831260681\n",
      "------------------------------\n",
      "Training model for stock ID 12\n",
      "(1, 44, 16)\n",
      "Threshold = 0.75\n",
      "Training data set size =  (1385, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.7359136343002319, Validation MAE = 0.603977382183075\n",
      "------------------------------\n",
      "Training model for stock ID 13\n",
      "(1, 95, 16)\n",
      "Threshold = 0.6499999999999999\n",
      "Training data set size =  (1715, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.761419951915741, Validation MAE = 0.3838372826576233\n",
      "------------------------------\n",
      "Training model for stock ID 14\n",
      "(1, 40, 16)\n",
      "Threshold = 0.6499999999999999\n",
      "Training data set size =  (1318, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.7311487197875977, Validation MAE = 0.5757741332054138\n",
      "------------------------------\n",
      "Training model for stock ID 15\n",
      "(1, 18, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (2134, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.6634986996650696, Validation MAE = 0.5369497537612915\n",
      "------------------------------\n",
      "Training model for stock ID 16\n",
      "(1, 50, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1736, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.805184543132782, Validation MAE = 0.5962197780609131\n",
      "------------------------------\n",
      "Training model for stock ID 17\n",
      "(1, 86, 16)\n",
      "Threshold = 0.6499999999999999\n",
      "Training data set size =  (1371, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8589585423469543, Validation MAE = 0.6609103083610535\n",
      "------------------------------\n",
      "Training model for stock ID 18\n",
      "(1, 71, 16)\n",
      "Threshold = 0.6499999999999999\n",
      "Training data set size =  (1097, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.6301707625389099, Validation MAE = 0.41144511103630066\n",
      "------------------------------\n",
      "Training model for stock ID 19\n",
      "(1, 88, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1470, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.7812961935997009, Validation MAE = 0.697101891040802\n",
      "------------------------------\n",
      "Training model for stock ID 20\n",
      "(1, 52, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1211, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8494295477867126, Validation MAE = 0.7949568033218384\n",
      "------------------------------\n",
      "Training model for stock ID 21\n",
      "(1, 52, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1619, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.6945579051971436, Validation MAE = 0.6158236861228943\n",
      "------------------------------\n",
      "Training model for stock ID 22\n",
      "(1, 37, 16)\n",
      "Threshold = 0.6499999999999999\n",
      "Training data set size =  (1447, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.6671701073646545, Validation MAE = 0.4550319314002991\n",
      "------------------------------\n",
      "Training model for stock ID 23\n",
      "(1, 1, 16)\n",
      "Threshold = 0.6499999999999999\n",
      "Training data set size =  (1057, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.7322019934654236, Validation MAE = 0.5626794695854187\n",
      "------------------------------\n",
      "Training model for stock ID 24\n",
      "(1, 35, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1444, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8383700251579285, Validation MAE = 0.6976613998413086\n",
      "------------------------------\n",
      "Training model for stock ID 25\n",
      "(1, 52, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1488, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8350046873092651, Validation MAE = 0.47966766357421875\n",
      "------------------------------\n",
      "Training model for stock ID 26\n",
      "(1, 76, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1368, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.789548397064209, Validation MAE = 0.6369984149932861\n",
      "------------------------------\n",
      "Training model for stock ID 27\n",
      "(1, 37, 16)\n",
      "Threshold = 0.6499999999999999\n",
      "Training data set size =  (1055, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.9129449129104614, Validation MAE = 0.6728091239929199\n",
      "------------------------------\n",
      "Training model for stock ID 28\n",
      "(1, 70, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (638, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8263658881187439, Validation MAE = 0.2943195104598999\n",
      "------------------------------\n",
      "Training model for stock ID 29\n",
      "(1, 25, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1330, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.792359471321106, Validation MAE = 0.5680650472640991\n",
      "------------------------------\n",
      "Training model for stock ID 30\n",
      "(1, 63, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1655, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8019208908081055, Validation MAE = 0.6984204649925232\n",
      "------------------------------\n",
      "Training model for stock ID 31\n",
      "(1, 69, 16)\n",
      "Threshold = 0.75\n",
      "Training data set size =  (1066, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.7149375081062317, Validation MAE = 0.8764557838439941\n",
      "------------------------------\n",
      "Training model for stock ID 32\n",
      "(1, 15, 16)\n",
      "Threshold = 0.44999999999999996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data set size =  (1504, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.9449955821037292, Validation MAE = 0.915200412273407\n",
      "------------------------------\n",
      "Training model for stock ID 33\n",
      "(1, 30, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1315, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8166882395744324, Validation MAE = 0.5693486332893372\n",
      "------------------------------\n",
      "Training model for stock ID 34\n",
      "(1, 19, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1732, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8817002773284912, Validation MAE = 0.8273182511329651\n",
      "------------------------------\n",
      "Training model for stock ID 35\n",
      "(1, 40, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1481, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8040090799331665, Validation MAE = 0.5831952095031738\n",
      "------------------------------\n",
      "Training model for stock ID 36\n",
      "(1, 30, 16)\n",
      "Threshold = 0.6499999999999999\n",
      "Training data set size =  (1152, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 1.1890380382537842, Validation MAE = 0.8223329782485962\n",
      "------------------------------\n",
      "Training model for stock ID 37\n",
      "(1, 47, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1535, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.855697512626648, Validation MAE = 0.514419436454773\n",
      "------------------------------\n",
      "Training model for stock ID 38\n",
      "(1, 26, 16)\n",
      "Threshold = 0.6499999999999999\n",
      "Training data set size =  (1139, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.9024637937545776, Validation MAE = 0.8783082962036133\n",
      "------------------------------\n",
      "Training model for stock ID 39\n",
      "(1, 62, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1295, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.9977751970291138, Validation MAE = 0.7744400501251221\n",
      "------------------------------\n",
      "Training model for stock ID 40\n",
      "(1, 115, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1580, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8247637152671814, Validation MAE = 0.45941320061683655\n",
      "------------------------------\n",
      "Training model for stock ID 41\n",
      "(1, 13, 16)\n",
      "Threshold = 0.6499999999999999\n",
      "Training data set size =  (1134, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8217958211898804, Validation MAE = 0.5943831205368042\n",
      "------------------------------\n",
      "Training model for stock ID 42\n",
      "(1, 6, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (339, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.9189379215240479, Validation MAE = 0.602152407169342\n",
      "------------------------------\n",
      "Training model for stock ID 43\n",
      "(1, 28, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1268, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.7993772625923157, Validation MAE = 0.4828066825866699\n",
      "------------------------------\n",
      "Training model for stock ID 44\n",
      "(1, 54, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1088, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.7981196045875549, Validation MAE = 0.5683794617652893\n",
      "------------------------------\n",
      "Training model for stock ID 45\n",
      "(1, 3, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1453, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8192028403282166, Validation MAE = 0.7607297897338867\n",
      "------------------------------\n",
      "Training model for stock ID 46\n",
      "(1, 0, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (39, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 4.133842468261719, Validation MAE = 2.561927556991577\n",
      "------------------------------\n",
      "Training model for stock ID 47\n",
      "(1, 61, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1019, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.7391990423202515, Validation MAE = 0.5617960691452026\n",
      "------------------------------\n",
      "Training model for stock ID 48\n",
      "(1, 55, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1108, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8319578766822815, Validation MAE = 0.5603727102279663\n",
      "------------------------------\n",
      "Training model for stock ID 49\n",
      "(1, 83, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1427, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8233708739280701, Validation MAE = 0.7459002733230591\n",
      "------------------------------\n",
      "Training model for stock ID 50\n",
      "(1, 58, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1087, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8784273862838745, Validation MAE = 0.7080716490745544\n",
      "------------------------------\n",
      "Training model for stock ID 51\n",
      "(1, 66, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1008, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.9103223085403442, Validation MAE = 0.6413146257400513\n",
      "------------------------------\n",
      "Training model for stock ID 52\n",
      "(1, 0, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (573, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 1.0439999103546143, Validation MAE = 0.8875017762184143\n",
      "------------------------------\n",
      "Training model for stock ID 53\n",
      "(1, 34, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1233, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8514073491096497, Validation MAE = 0.5495031476020813\n",
      "------------------------------\n",
      "Training model for stock ID 54\n",
      "(1, 10, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1028, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.750461995601654, Validation MAE = 0.6028435230255127\n",
      "------------------------------\n",
      "Training model for stock ID 55\n",
      "(1, 0, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1265, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.7992309927940369, Validation MAE = 0.4504595696926117\n",
      "------------------------------\n",
      "Training model for stock ID 56\n",
      "(1, 96, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1186, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8410816192626953, Validation MAE = 0.8242851495742798\n",
      "------------------------------\n",
      "Training model for stock ID 57\n",
      "(1, 18, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1488, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8120341897010803, Validation MAE = 0.8499562740325928\n",
      "------------------------------\n",
      "Training model for stock ID 58\n",
      "(1, 17, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1448, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.7941678762435913, Validation MAE = 0.7151263356208801\n",
      "------------------------------\n",
      "Training model for stock ID 59\n",
      "(1, 0, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (961, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.7423548102378845, Validation MAE = 0.5004506707191467\n",
      "------------------------------\n",
      "Training model for stock ID 60\n",
      "(1, 0, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (436, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.6948950290679932, Validation MAE = 0.3018716871738434\n",
      "------------------------------\n",
      "Training model for stock ID 61\n",
      "(1, 87, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1025, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.9124091863632202, Validation MAE = 0.8874986171722412\n",
      "------------------------------\n",
      "Training model for stock ID 62\n",
      "(1, 19, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1027, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.700003445148468, Validation MAE = 0.7790346145629883\n",
      "------------------------------\n",
      "Training model for stock ID 63\n",
      "(1, 9, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1197, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8119509816169739, Validation MAE = 0.6892244815826416\n",
      "------------------------------\n",
      "Training model for stock ID 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 21, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (914, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.7397549152374268, Validation MAE = 0.6951972246170044\n",
      "------------------------------\n",
      "Training model for stock ID 65\n",
      "(1, 10, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1322, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.870607852935791, Validation MAE = 0.7087659239768982\n",
      "------------------------------\n",
      "Training model for stock ID 66\n",
      "(1, 42, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (819, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8672786951065063, Validation MAE = 0.9588919878005981\n",
      "------------------------------\n",
      "Training model for stock ID 67\n",
      "(1, 30, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1468, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.9225841164588928, Validation MAE = 0.8200339674949646\n",
      "------------------------------\n",
      "Training model for stock ID 68\n",
      "(1, 27, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (895, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.7565882802009583, Validation MAE = 0.720206081867218\n",
      "------------------------------\n",
      "Training model for stock ID 69\n",
      "(1, 0, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (710, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.9180765748023987, Validation MAE = 0.7413720488548279\n",
      "------------------------------\n",
      "Training model for stock ID 70\n",
      "(1, 87, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1344, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.7027499079704285, Validation MAE = 0.7216997146606445\n",
      "------------------------------\n",
      "Training model for stock ID 71\n",
      "(1, 2, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1352, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8344489932060242, Validation MAE = 0.7421075701713562\n",
      "------------------------------\n",
      "Training model for stock ID 72\n",
      "(1, 37, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1590, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8569296598434448, Validation MAE = 0.4266490042209625\n",
      "------------------------------\n",
      "Training model for stock ID 73\n",
      "(1, 34, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1136, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.9269924759864807, Validation MAE = 0.8131213784217834\n",
      "------------------------------\n",
      "Training model for stock ID 74\n",
      "(1, 21, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1572, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.7090523838996887, Validation MAE = 0.4669763147830963\n",
      "------------------------------\n",
      "Training model for stock ID 75\n",
      "(1, 17, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1695, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.9327711462974548, Validation MAE = 0.5545908808708191\n",
      "------------------------------\n",
      "Training model for stock ID 76\n",
      "(1, 63, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1345, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8718173503875732, Validation MAE = 0.6898856163024902\n",
      "------------------------------\n",
      "Training model for stock ID 77\n",
      "(1, 22, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1145, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.9062501192092896, Validation MAE = 0.7052727341651917\n",
      "------------------------------\n",
      "Training model for stock ID 78\n",
      "(1, 31, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (777, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.9100455641746521, Validation MAE = 0.43251219391822815\n",
      "------------------------------\n",
      "Training model for stock ID 79\n",
      "(1, 0, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (712, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.9146165251731873, Validation MAE = 0.4628055989742279\n",
      "------------------------------\n",
      "Training model for stock ID 80\n",
      "(1, 57, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1354, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.7838213443756104, Validation MAE = 0.6081735491752625\n",
      "------------------------------\n",
      "Training model for stock ID 81\n",
      "(1, 61, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1664, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.7994005680084229, Validation MAE = 0.6978470087051392\n",
      "------------------------------\n",
      "Training model for stock ID 82\n",
      "(1, 114, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1528, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.7011665105819702, Validation MAE = 0.6499090194702148\n",
      "------------------------------\n",
      "Training model for stock ID 83\n",
      "(1, 0, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1590, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.767647385597229, Validation MAE = 0.5175303816795349\n",
      "------------------------------\n",
      "Training model for stock ID 84\n",
      "(1, 2, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1168, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8193899393081665, Validation MAE = 0.4593322277069092\n",
      "------------------------------\n",
      "Training model for stock ID 85\n",
      "(1, 21, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (919, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.7504422068595886, Validation MAE = 0.5984170436859131\n",
      "------------------------------\n",
      "Training model for stock ID 86\n",
      "(1, 89, 16)\n",
      "Threshold = 0.6499999999999999\n",
      "Training data set size =  (1092, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8101687431335449, Validation MAE = 0.8488187789916992\n",
      "------------------------------\n",
      "Training model for stock ID 87\n",
      "(1, 4, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (773, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.9521912336349487, Validation MAE = 0.9385086297988892\n",
      "------------------------------\n",
      "Training model for stock ID 88\n",
      "(1, 5, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1377, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8809101581573486, Validation MAE = 0.8741289377212524\n",
      "------------------------------\n",
      "Training model for stock ID 89\n",
      "(1, 0, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1054, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.7830219864845276, Validation MAE = 0.45301809906959534\n",
      "------------------------------\n",
      "Training model for stock ID 90\n",
      "(1, 63, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (985, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.7456990480422974, Validation MAE = 0.6850332617759705\n",
      "------------------------------\n",
      "Training model for stock ID 91\n",
      "(1, 29, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1162, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.7933105826377869, Validation MAE = 0.36031705141067505\n",
      "------------------------------\n",
      "Training model for stock ID 92\n",
      "(1, 23, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1070, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.7299214601516724, Validation MAE = 0.534796416759491\n",
      "------------------------------\n",
      "Training model for stock ID 93\n",
      "(1, 23, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1082, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.816112756729126, Validation MAE = 0.4910486340522766\n",
      "------------------------------\n",
      "Training model for stock ID 94\n",
      "(1, 85, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1274, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.7985846996307373, Validation MAE = 0.5734083652496338\n",
      "------------------------------\n",
      "Training model for stock ID 95\n",
      "(1, 27, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1282, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.9525313973426819, Validation MAE = 0.5528530478477478\n",
      "------------------------------\n",
      "Training model for stock ID 96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 68, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1049, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.9378141760826111, Validation MAE = 0.7528418898582458\n",
      "------------------------------\n",
      "Training model for stock ID 97\n",
      "(1, 36, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1136, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.9095420241355896, Validation MAE = 0.6692285537719727\n",
      "------------------------------\n",
      "Training model for stock ID 98\n",
      "(1, 34, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1071, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8948293328285217, Validation MAE = 0.4837295114994049\n",
      "------------------------------\n",
      "Training model for stock ID 99\n",
      "(1, 0, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1001, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8247239589691162, Validation MAE = 0.7731720209121704\n",
      "------------------------------\n",
      "Training model for stock ID 100\n",
      "(1, 0, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (235, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.9107398390769958, Validation MAE = 0.6701898574829102\n",
      "------------------------------\n",
      "Training model for stock ID 101\n",
      "(1, 13, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (883, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8018734455108643, Validation MAE = 0.5990964770317078\n",
      "------------------------------\n",
      "Training model for stock ID 102\n",
      "(1, 45, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (232, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 1.2966474294662476, Validation MAE = 1.369349479675293\n",
      "------------------------------\n",
      "Training model for stock ID 103\n",
      "(1, 23, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (739, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.7765299677848816, Validation MAE = 0.6549846529960632\n",
      "------------------------------\n",
      "Training model for stock ID 104\n",
      "(1, 54, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1621, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8827752470970154, Validation MAE = 1.1798020601272583\n",
      "------------------------------\n",
      "Training model for stock ID 105\n",
      "(1, 11, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1123, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8357146978378296, Validation MAE = 0.4674590528011322\n",
      "------------------------------\n",
      "Training model for stock ID 106\n",
      "(1, 31, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1072, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.852321982383728, Validation MAE = 0.4708133637905121\n",
      "------------------------------\n",
      "Training model for stock ID 107\n",
      "(1, 1, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (312, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.839095950126648, Validation MAE = 0.7311915755271912\n",
      "------------------------------\n",
      "Training model for stock ID 108\n",
      "(1, 28, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (954, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.9043887853622437, Validation MAE = 0.8279306292533875\n",
      "------------------------------\n",
      "Training model for stock ID 109\n",
      "(1, 22, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1603, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.7666043639183044, Validation MAE = 0.38189539313316345\n",
      "------------------------------\n",
      "Training model for stock ID 110\n",
      "(1, 9, 16)\n",
      "Threshold = 0.6499999999999999\n",
      "Training data set size =  (1060, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8131789565086365, Validation MAE = 0.5866807699203491\n",
      "------------------------------\n",
      "Training model for stock ID 111\n",
      "(1, 1, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (147, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.7561041116714478, Validation MAE = 0.511420488357544\n",
      "------------------------------\n",
      "Training model for stock ID 112\n",
      "(1, 0, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1532, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.7579209208488464, Validation MAE = 0.5469393730163574\n",
      "------------------------------\n",
      "Training model for stock ID 113\n",
      "(1, 71, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (846, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8590469360351562, Validation MAE = 0.9533568620681763\n",
      "------------------------------\n",
      "Training model for stock ID 114\n",
      "(1, 103, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1125, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.9016202092170715, Validation MAE = 1.1961729526519775\n",
      "------------------------------\n",
      "Training model for stock ID 115\n",
      "(1, 91, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1099, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.7458149790763855, Validation MAE = 0.7057032585144043\n",
      "------------------------------\n",
      "Training model for stock ID 116\n",
      "(1, 28, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1075, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 1.126497745513916, Validation MAE = 0.9692994356155396\n",
      "------------------------------\n",
      "Training model for stock ID 117\n",
      "(1, 45, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1004, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 1.007814884185791, Validation MAE = 0.5208771824836731\n",
      "------------------------------\n",
      "Training model for stock ID 118\n",
      "(1, 63, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1380, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8544132709503174, Validation MAE = 0.694174587726593\n",
      "------------------------------\n",
      "Training model for stock ID 119\n",
      "(1, 87, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (978, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.9227131605148315, Validation MAE = 0.5044625401496887\n",
      "------------------------------\n",
      "Training model for stock ID 120\n",
      "(1, 0, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (956, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.9025880098342896, Validation MAE = 0.8303623199462891\n",
      "------------------------------\n",
      "Training model for stock ID 121\n",
      "(1, 27, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1165, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8438515663146973, Validation MAE = 0.6622830629348755\n",
      "------------------------------\n",
      "Training model for stock ID 122\n",
      "(1, 60, 16)\n",
      "Threshold = 0.6499999999999999\n",
      "Training data set size =  (1044, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.7991300821304321, Validation MAE = 0.6525087952613831\n",
      "------------------------------\n",
      "Training model for stock ID 123\n",
      "(1, 51, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1354, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.880975067615509, Validation MAE = 1.0770756006240845\n",
      "------------------------------\n",
      "Training model for stock ID 124\n",
      "(1, 22, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (772, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 1.0793988704681396, Validation MAE = 1.1284198760986328\n",
      "------------------------------\n",
      "Training model for stock ID 125\n",
      "(1, 8, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1212, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.9299162030220032, Validation MAE = 0.7082887887954712\n",
      "------------------------------\n",
      "Training model for stock ID 126\n",
      "(1, 2, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1431, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8940339088439941, Validation MAE = 1.4157034158706665\n",
      "------------------------------\n",
      "Training model for stock ID 127\n",
      "(1, 5, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1289, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8133981227874756, Validation MAE = 0.6690557599067688\n",
      "------------------------------\n",
      "Training model for stock ID 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 16, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1005, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8733794689178467, Validation MAE = 0.6231144070625305\n",
      "------------------------------\n",
      "Training model for stock ID 129\n",
      "(1, 43, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (977, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.9453544020652771, Validation MAE = 0.6061013340950012\n",
      "------------------------------\n",
      "Training model for stock ID 130\n",
      "(1, 1, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1247, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.7928402423858643, Validation MAE = 0.532344400882721\n",
      "------------------------------\n",
      "Training model for stock ID 131\n",
      "(1, 27, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (666, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 1.0160295963287354, Validation MAE = 0.9178948402404785\n",
      "------------------------------\n",
      "Training model for stock ID 132\n",
      "(1, 22, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1520, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8514246940612793, Validation MAE = 1.0078866481781006\n",
      "------------------------------\n",
      "Training model for stock ID 133\n",
      "(1, 15, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1403, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8182774186134338, Validation MAE = 0.477817177772522\n",
      "------------------------------\n",
      "Training model for stock ID 134\n",
      "(1, 32, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1196, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.7892904877662659, Validation MAE = 0.7338575124740601\n",
      "------------------------------\n",
      "Training model for stock ID 135\n",
      "(1, 1, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (672, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8855845928192139, Validation MAE = 0.5861068367958069\n",
      "------------------------------\n",
      "Training model for stock ID 136\n",
      "(1, 7, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1009, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8243921995162964, Validation MAE = 0.9626411199569702\n",
      "------------------------------\n",
      "Training model for stock ID 137\n",
      "(1, 13, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (443, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 1.1001874208450317, Validation MAE = 0.9602630734443665\n",
      "------------------------------\n",
      "Training model for stock ID 138\n",
      "(1, 76, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1049, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.9004276394844055, Validation MAE = 1.1962757110595703\n",
      "------------------------------\n",
      "Training model for stock ID 139\n",
      "(1, 55, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1074, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8567894697189331, Validation MAE = 0.6361379027366638\n",
      "------------------------------\n",
      "Training model for stock ID 140\n",
      "(1, 17, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1543, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 1.009549617767334, Validation MAE = 0.7469543218612671\n",
      "------------------------------\n",
      "Training model for stock ID 141\n",
      "(1, 18, 16)\n",
      "Threshold = 0.6499999999999999\n",
      "Training data set size =  (1088, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8309450149536133, Validation MAE = 0.9480808973312378\n",
      "------------------------------\n",
      "Training model for stock ID 142\n",
      "(1, 4, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1440, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8024129271507263, Validation MAE = 0.4949837327003479\n",
      "------------------------------\n",
      "Training model for stock ID 143\n",
      "(1, 47, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1050, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8794435858726501, Validation MAE = 0.49046778678894043\n",
      "------------------------------\n",
      "Training model for stock ID 144\n",
      "(1, 23, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (970, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8263475298881531, Validation MAE = 0.7927505970001221\n",
      "------------------------------\n",
      "Training model for stock ID 145\n",
      "(1, 3, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1223, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8902262449264526, Validation MAE = 0.4962638020515442\n",
      "------------------------------\n",
      "Training model for stock ID 146\n",
      "(1, 14, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1117, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8000273108482361, Validation MAE = 0.7424780130386353\n",
      "------------------------------\n",
      "Training model for stock ID 147\n",
      "(1, 42, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1207, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8680920600891113, Validation MAE = 1.1181433200836182\n",
      "------------------------------\n",
      "Training model for stock ID 148\n",
      "(1, 18, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1207, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8109904527664185, Validation MAE = 0.7472555637359619\n",
      "------------------------------\n",
      "Training model for stock ID 149\n",
      "(1, 39, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1166, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8549811840057373, Validation MAE = 0.5193567276000977\n",
      "------------------------------\n",
      "Training model for stock ID 150\n",
      "(1, 19, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (762, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.7919914722442627, Validation MAE = 0.4744299650192261\n",
      "------------------------------\n",
      "Training model for stock ID 151\n",
      "(1, 0, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1195, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 1.0121126174926758, Validation MAE = 0.9699403047561646\n",
      "------------------------------\n",
      "Training model for stock ID 152\n",
      "(1, 22, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1292, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.824741780757904, Validation MAE = 0.5304290652275085\n",
      "------------------------------\n",
      "Training model for stock ID 153\n",
      "(1, 0, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (243, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 1.14271879196167, Validation MAE = 0.46311071515083313\n",
      "------------------------------\n",
      "Training model for stock ID 154\n",
      "(1, 0, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (850, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8886116743087769, Validation MAE = 0.7883775234222412\n",
      "------------------------------\n",
      "Training model for stock ID 155\n",
      "(1, 20, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (667, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8541324734687805, Validation MAE = 0.4286075532436371\n",
      "------------------------------\n",
      "Training model for stock ID 156\n",
      "(1, 22, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1092, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 1.05106782913208, Validation MAE = 0.5515130162239075\n",
      "------------------------------\n",
      "Training model for stock ID 157\n",
      "(1, 16, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1081, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8713768124580383, Validation MAE = 0.5429195761680603\n",
      "------------------------------\n",
      "Training model for stock ID 158\n",
      "(1, 2, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1311, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.7227324843406677, Validation MAE = 0.5618585348129272\n",
      "------------------------------\n",
      "Training model for stock ID 159\n",
      "(1, 0, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (81, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 3.2636055946350098, Validation MAE = 0.8376263976097107\n",
      "------------------------------\n",
      "Training model for stock ID 160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1249, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8852183222770691, Validation MAE = 0.8880811333656311\n",
      "------------------------------\n",
      "Training model for stock ID 161\n",
      "(1, 48, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1408, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.9320746064186096, Validation MAE = 0.8165134191513062\n",
      "------------------------------\n",
      "Training model for stock ID 162\n",
      "(1, 0, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (747, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.9202786087989807, Validation MAE = 0.897783100605011\n",
      "------------------------------\n",
      "Training model for stock ID 163\n",
      "(1, 9, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1175, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.7582001090049744, Validation MAE = 0.4384823739528656\n",
      "------------------------------\n",
      "Training model for stock ID 164\n",
      "(1, 3, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1159, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.7682231068611145, Validation MAE = 0.6454418897628784\n",
      "------------------------------\n",
      "Training model for stock ID 165\n",
      "(1, 0, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1459, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8153463006019592, Validation MAE = 0.7477673292160034\n",
      "------------------------------\n",
      "Training model for stock ID 166\n",
      "(1, 8, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1120, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 1.0624176263809204, Validation MAE = 0.6024103164672852\n",
      "------------------------------\n",
      "Training model for stock ID 167\n",
      "(1, 0, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (999, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 1.1111538410186768, Validation MAE = 0.6994677186012268\n",
      "------------------------------\n",
      "Training model for stock ID 168\n",
      "(1, 1, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1540, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.9462587833404541, Validation MAE = 0.7933401465415955\n",
      "------------------------------\n",
      "Training model for stock ID 169\n",
      "(1, 33, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1557, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.9304815530776978, Validation MAE = 0.6039438843727112\n",
      "------------------------------\n",
      "Training model for stock ID 170\n",
      "(1, 9, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1078, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8140377402305603, Validation MAE = 0.8004978895187378\n",
      "------------------------------\n",
      "Training model for stock ID 171\n",
      "(1, 0, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1087, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8600660562515259, Validation MAE = 0.7927918434143066\n",
      "------------------------------\n",
      "Training model for stock ID 172\n",
      "(1, 0, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (176, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 1.2943730354309082, Validation MAE = 0.9075132608413696\n",
      "------------------------------\n",
      "Training model for stock ID 173\n",
      "(1, 62, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1090, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8415212631225586, Validation MAE = 0.8990359902381897\n",
      "------------------------------\n",
      "Training model for stock ID 174\n",
      "(1, 0, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (662, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.6894973516464233, Validation MAE = 0.3002825379371643\n",
      "------------------------------\n",
      "Training model for stock ID 175\n",
      "(1, 17, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1493, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8234803676605225, Validation MAE = 0.6208695769309998\n",
      "------------------------------\n",
      "Training model for stock ID 176\n",
      "(1, 17, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1251, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.7762866616249084, Validation MAE = 0.6818139553070068\n",
      "------------------------------\n",
      "Training model for stock ID 177\n",
      "(1, 41, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1052, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8604000210762024, Validation MAE = 0.6549416184425354\n",
      "------------------------------\n",
      "Training model for stock ID 178\n",
      "(1, 53, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1082, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.788238525390625, Validation MAE = 0.5574681758880615\n",
      "------------------------------\n",
      "Training model for stock ID 179\n",
      "(1, 2, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1220, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8346091508865356, Validation MAE = 0.6809923648834229\n",
      "------------------------------\n",
      "Training model for stock ID 180\n",
      "(1, 0, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1138, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.7747582793235779, Validation MAE = 0.7003347873687744\n",
      "------------------------------\n",
      "Training model for stock ID 181\n",
      "(1, 3, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1037, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8414296507835388, Validation MAE = 0.7468650341033936\n",
      "------------------------------\n",
      "Training model for stock ID 182\n",
      "(1, 44, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1229, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.7854903936386108, Validation MAE = 0.9244170188903809\n",
      "------------------------------\n",
      "Training model for stock ID 183\n",
      "(1, 0, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1203, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.7767554521560669, Validation MAE = 0.7220613956451416\n",
      "------------------------------\n",
      "Training model for stock ID 184\n",
      "(1, 60, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1335, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8732414841651917, Validation MAE = 0.5228534936904907\n",
      "------------------------------\n",
      "Training model for stock ID 185\n",
      "(1, 0, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (61, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 3.0495963096618652, Validation MAE = 0.9661267995834351\n",
      "------------------------------\n",
      "Training model for stock ID 186\n",
      "(1, 110, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1079, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.9305590391159058, Validation MAE = 0.7770194411277771\n",
      "------------------------------\n",
      "Training model for stock ID 187\n",
      "(1, 21, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1065, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8323962092399597, Validation MAE = 0.5804766416549683\n",
      "------------------------------\n",
      "Training model for stock ID 188\n",
      "(1, 14, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1353, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8004329204559326, Validation MAE = 0.5876975059509277\n",
      "------------------------------\n",
      "Training model for stock ID 189\n",
      "(1, 0, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (262, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.5337194800376892, Validation MAE = 0.5805308818817139\n",
      "------------------------------\n",
      "Training model for stock ID 190\n",
      "(1, 52, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1556, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8887357115745544, Validation MAE = 0.770042896270752\n",
      "------------------------------\n",
      "Training model for stock ID 191\n",
      "(1, 33, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1413, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.725786566734314, Validation MAE = 0.4612414836883545\n",
      "------------------------------\n",
      "Training model for stock ID 192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 29, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (855, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.7645357251167297, Validation MAE = 0.44793665409088135\n",
      "------------------------------\n",
      "Training model for stock ID 193\n",
      "(1, 16, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1089, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.9252426028251648, Validation MAE = 0.7753530144691467\n",
      "------------------------------\n",
      "Training model for stock ID 194\n",
      "(1, 30, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (918, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8198148608207703, Validation MAE = 0.5134080648422241\n",
      "------------------------------\n",
      "Training model for stock ID 195\n",
      "(1, 63, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1133, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8119176030158997, Validation MAE = 0.8312662839889526\n",
      "------------------------------\n",
      "Training model for stock ID 196\n",
      "(1, 41, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (1104, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8481304049491882, Validation MAE = 0.5946464538574219\n",
      "------------------------------\n",
      "Training model for stock ID 197\n",
      "(1, 3, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (974, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 1.0181583166122437, Validation MAE = 1.084992527961731\n",
      "------------------------------\n",
      "Training model for stock ID 198\n",
      "(1, 1, 16)\n",
      "Threshold = 0.5499999999999999\n",
      "Training data set size =  (1200, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.9346683025360107, Validation MAE = 0.8367197513580322\n",
      "------------------------------\n",
      "Training model for stock ID 199\n",
      "(1, 0, 16)\n",
      "Threshold = 0.44999999999999996\n",
      "Training data set size =  (476, 55, 16)\n",
      "Validation data set size =  (165, 55, 16)\n",
      "Training MAE = 0.8746449947357178, Validation MAE = 0.5147013068199158\n",
      "------------------------------\n",
      "CPU times: total: 2h 38min 31s\n",
      "Wall time: 22min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#threshold_list = [0.95, 0.9, 0.8, 0.7] \n",
    "threshold_list = [0.95]\n",
    "\n",
    "for threshold in threshold_list:\n",
    "\n",
    "    print('Cosine similarity threshold = ', threshold)\n",
    "    train_models(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MAEs of the models are: -\n",
      "Stock ID = 0, Cosine similarity threshold = 0.95, Training MAE = 0.7623547911643982, Validation MAE = 0.7081812620162964\n",
      "Stock ID = 1, Cosine similarity threshold = 0.95, Training MAE = 0.7468001246452332, Validation MAE = 0.6311120986938477\n",
      "Stock ID = 2, Cosine similarity threshold = 0.95, Training MAE = 0.8455199599266052, Validation MAE = 0.8830938339233398\n",
      "Stock ID = 3, Cosine similarity threshold = 0.95, Training MAE = 0.7316550612449646, Validation MAE = 0.5541003346443176\n",
      "Stock ID = 4, Cosine similarity threshold = 0.95, Training MAE = 0.6467030644416809, Validation MAE = 0.5069093704223633\n",
      "Stock ID = 5, Cosine similarity threshold = 0.95, Training MAE = 0.6203770041465759, Validation MAE = 0.38522112369537354\n",
      "Stock ID = 6, Cosine similarity threshold = 0.95, Training MAE = 0.6207630634307861, Validation MAE = 0.6588804125785828\n",
      "Stock ID = 7, Cosine similarity threshold = 0.95, Training MAE = 0.49060478806495667, Validation MAE = 0.38904255628585815\n",
      "Stock ID = 8, Cosine similarity threshold = 0.95, Training MAE = 0.6820960640907288, Validation MAE = 0.5763413906097412\n",
      "Stock ID = 9, Cosine similarity threshold = 0.95, Training MAE = 0.7562897801399231, Validation MAE = 0.8097860813140869\n",
      "Stock ID = 10, Cosine similarity threshold = 0.95, Training MAE = 0.6591199636459351, Validation MAE = 0.592311441898346\n",
      "Stock ID = 11, Cosine similarity threshold = 0.95, Training MAE = 0.782374918460846, Validation MAE = 0.3660110831260681\n",
      "Stock ID = 12, Cosine similarity threshold = 0.95, Training MAE = 0.7359136343002319, Validation MAE = 0.603977382183075\n",
      "Stock ID = 13, Cosine similarity threshold = 0.95, Training MAE = 0.761419951915741, Validation MAE = 0.3838372826576233\n",
      "Stock ID = 14, Cosine similarity threshold = 0.95, Training MAE = 0.7311487197875977, Validation MAE = 0.5757741332054138\n",
      "Stock ID = 15, Cosine similarity threshold = 0.95, Training MAE = 0.6634986996650696, Validation MAE = 0.5369497537612915\n",
      "Stock ID = 16, Cosine similarity threshold = 0.95, Training MAE = 0.805184543132782, Validation MAE = 0.5962197780609131\n",
      "Stock ID = 17, Cosine similarity threshold = 0.95, Training MAE = 0.8589585423469543, Validation MAE = 0.6609103083610535\n",
      "Stock ID = 18, Cosine similarity threshold = 0.95, Training MAE = 0.6301707625389099, Validation MAE = 0.41144511103630066\n",
      "Stock ID = 19, Cosine similarity threshold = 0.95, Training MAE = 0.7812961935997009, Validation MAE = 0.697101891040802\n",
      "Stock ID = 20, Cosine similarity threshold = 0.95, Training MAE = 0.8494295477867126, Validation MAE = 0.7949568033218384\n",
      "Stock ID = 21, Cosine similarity threshold = 0.95, Training MAE = 0.6945579051971436, Validation MAE = 0.6158236861228943\n",
      "Stock ID = 22, Cosine similarity threshold = 0.95, Training MAE = 0.6671701073646545, Validation MAE = 0.4550319314002991\n",
      "Stock ID = 23, Cosine similarity threshold = 0.95, Training MAE = 0.7322019934654236, Validation MAE = 0.5626794695854187\n",
      "Stock ID = 24, Cosine similarity threshold = 0.95, Training MAE = 0.8383700251579285, Validation MAE = 0.6976613998413086\n",
      "Stock ID = 25, Cosine similarity threshold = 0.95, Training MAE = 0.8350046873092651, Validation MAE = 0.47966766357421875\n",
      "Stock ID = 26, Cosine similarity threshold = 0.95, Training MAE = 0.789548397064209, Validation MAE = 0.6369984149932861\n",
      "Stock ID = 27, Cosine similarity threshold = 0.95, Training MAE = 0.9129449129104614, Validation MAE = 0.6728091239929199\n",
      "Stock ID = 28, Cosine similarity threshold = 0.95, Training MAE = 0.8263658881187439, Validation MAE = 0.2943195104598999\n",
      "Stock ID = 29, Cosine similarity threshold = 0.95, Training MAE = 0.792359471321106, Validation MAE = 0.5680650472640991\n",
      "Stock ID = 30, Cosine similarity threshold = 0.95, Training MAE = 0.8019208908081055, Validation MAE = 0.6984204649925232\n",
      "Stock ID = 31, Cosine similarity threshold = 0.95, Training MAE = 0.7149375081062317, Validation MAE = 0.8764557838439941\n",
      "Stock ID = 32, Cosine similarity threshold = 0.95, Training MAE = 0.9449955821037292, Validation MAE = 0.915200412273407\n",
      "Stock ID = 33, Cosine similarity threshold = 0.95, Training MAE = 0.8166882395744324, Validation MAE = 0.5693486332893372\n",
      "Stock ID = 34, Cosine similarity threshold = 0.95, Training MAE = 0.8817002773284912, Validation MAE = 0.8273182511329651\n",
      "Stock ID = 35, Cosine similarity threshold = 0.95, Training MAE = 0.8040090799331665, Validation MAE = 0.5831952095031738\n",
      "Stock ID = 36, Cosine similarity threshold = 0.95, Training MAE = 1.1890380382537842, Validation MAE = 0.8223329782485962\n",
      "Stock ID = 37, Cosine similarity threshold = 0.95, Training MAE = 0.855697512626648, Validation MAE = 0.514419436454773\n",
      "Stock ID = 38, Cosine similarity threshold = 0.95, Training MAE = 0.9024637937545776, Validation MAE = 0.8783082962036133\n",
      "Stock ID = 39, Cosine similarity threshold = 0.95, Training MAE = 0.9977751970291138, Validation MAE = 0.7744400501251221\n",
      "Stock ID = 40, Cosine similarity threshold = 0.95, Training MAE = 0.8247637152671814, Validation MAE = 0.45941320061683655\n",
      "Stock ID = 41, Cosine similarity threshold = 0.95, Training MAE = 0.8217958211898804, Validation MAE = 0.5943831205368042\n",
      "Stock ID = 42, Cosine similarity threshold = 0.95, Training MAE = 0.9189379215240479, Validation MAE = 0.602152407169342\n",
      "Stock ID = 43, Cosine similarity threshold = 0.95, Training MAE = 0.7993772625923157, Validation MAE = 0.4828066825866699\n",
      "Stock ID = 44, Cosine similarity threshold = 0.95, Training MAE = 0.7981196045875549, Validation MAE = 0.5683794617652893\n",
      "Stock ID = 45, Cosine similarity threshold = 0.95, Training MAE = 0.8192028403282166, Validation MAE = 0.7607297897338867\n",
      "Stock ID = 46, Cosine similarity threshold = 0.95, Training MAE = 4.133842468261719, Validation MAE = 2.561927556991577\n",
      "Stock ID = 47, Cosine similarity threshold = 0.95, Training MAE = 0.7391990423202515, Validation MAE = 0.5617960691452026\n",
      "Stock ID = 48, Cosine similarity threshold = 0.95, Training MAE = 0.8319578766822815, Validation MAE = 0.5603727102279663\n",
      "Stock ID = 49, Cosine similarity threshold = 0.95, Training MAE = 0.8233708739280701, Validation MAE = 0.7459002733230591\n",
      "Stock ID = 50, Cosine similarity threshold = 0.95, Training MAE = 0.8784273862838745, Validation MAE = 0.7080716490745544\n",
      "Stock ID = 51, Cosine similarity threshold = 0.95, Training MAE = 0.9103223085403442, Validation MAE = 0.6413146257400513\n",
      "Stock ID = 52, Cosine similarity threshold = 0.95, Training MAE = 1.0439999103546143, Validation MAE = 0.8875017762184143\n",
      "Stock ID = 53, Cosine similarity threshold = 0.95, Training MAE = 0.8514073491096497, Validation MAE = 0.5495031476020813\n",
      "Stock ID = 54, Cosine similarity threshold = 0.95, Training MAE = 0.750461995601654, Validation MAE = 0.6028435230255127\n",
      "Stock ID = 55, Cosine similarity threshold = 0.95, Training MAE = 0.7992309927940369, Validation MAE = 0.4504595696926117\n",
      "Stock ID = 56, Cosine similarity threshold = 0.95, Training MAE = 0.8410816192626953, Validation MAE = 0.8242851495742798\n",
      "Stock ID = 57, Cosine similarity threshold = 0.95, Training MAE = 0.8120341897010803, Validation MAE = 0.8499562740325928\n",
      "Stock ID = 58, Cosine similarity threshold = 0.95, Training MAE = 0.7941678762435913, Validation MAE = 0.7151263356208801\n",
      "Stock ID = 59, Cosine similarity threshold = 0.95, Training MAE = 0.7423548102378845, Validation MAE = 0.5004506707191467\n",
      "Stock ID = 60, Cosine similarity threshold = 0.95, Training MAE = 0.6948950290679932, Validation MAE = 0.3018716871738434\n",
      "Stock ID = 61, Cosine similarity threshold = 0.95, Training MAE = 0.9124091863632202, Validation MAE = 0.8874986171722412\n",
      "Stock ID = 62, Cosine similarity threshold = 0.95, Training MAE = 0.700003445148468, Validation MAE = 0.7790346145629883\n",
      "Stock ID = 63, Cosine similarity threshold = 0.95, Training MAE = 0.8119509816169739, Validation MAE = 0.6892244815826416\n",
      "Stock ID = 64, Cosine similarity threshold = 0.95, Training MAE = 0.7397549152374268, Validation MAE = 0.6951972246170044\n",
      "Stock ID = 65, Cosine similarity threshold = 0.95, Training MAE = 0.870607852935791, Validation MAE = 0.7087659239768982\n",
      "Stock ID = 66, Cosine similarity threshold = 0.95, Training MAE = 0.8672786951065063, Validation MAE = 0.9588919878005981\n",
      "Stock ID = 67, Cosine similarity threshold = 0.95, Training MAE = 0.9225841164588928, Validation MAE = 0.8200339674949646\n",
      "Stock ID = 68, Cosine similarity threshold = 0.95, Training MAE = 0.7565882802009583, Validation MAE = 0.720206081867218\n",
      "Stock ID = 69, Cosine similarity threshold = 0.95, Training MAE = 0.9180765748023987, Validation MAE = 0.7413720488548279\n",
      "Stock ID = 70, Cosine similarity threshold = 0.95, Training MAE = 0.7027499079704285, Validation MAE = 0.7216997146606445\n",
      "Stock ID = 71, Cosine similarity threshold = 0.95, Training MAE = 0.8344489932060242, Validation MAE = 0.7421075701713562\n",
      "Stock ID = 72, Cosine similarity threshold = 0.95, Training MAE = 0.8569296598434448, Validation MAE = 0.4266490042209625\n",
      "Stock ID = 73, Cosine similarity threshold = 0.95, Training MAE = 0.9269924759864807, Validation MAE = 0.8131213784217834\n",
      "Stock ID = 74, Cosine similarity threshold = 0.95, Training MAE = 0.7090523838996887, Validation MAE = 0.4669763147830963\n",
      "Stock ID = 75, Cosine similarity threshold = 0.95, Training MAE = 0.9327711462974548, Validation MAE = 0.5545908808708191\n",
      "Stock ID = 76, Cosine similarity threshold = 0.95, Training MAE = 0.8718173503875732, Validation MAE = 0.6898856163024902\n",
      "Stock ID = 77, Cosine similarity threshold = 0.95, Training MAE = 0.9062501192092896, Validation MAE = 0.7052727341651917\n",
      "Stock ID = 78, Cosine similarity threshold = 0.95, Training MAE = 0.9100455641746521, Validation MAE = 0.43251219391822815\n",
      "Stock ID = 79, Cosine similarity threshold = 0.95, Training MAE = 0.9146165251731873, Validation MAE = 0.4628055989742279\n",
      "Stock ID = 80, Cosine similarity threshold = 0.95, Training MAE = 0.7838213443756104, Validation MAE = 0.6081735491752625\n",
      "Stock ID = 81, Cosine similarity threshold = 0.95, Training MAE = 0.7994005680084229, Validation MAE = 0.6978470087051392\n",
      "Stock ID = 82, Cosine similarity threshold = 0.95, Training MAE = 0.7011665105819702, Validation MAE = 0.6499090194702148\n",
      "Stock ID = 83, Cosine similarity threshold = 0.95, Training MAE = 0.767647385597229, Validation MAE = 0.5175303816795349\n",
      "Stock ID = 84, Cosine similarity threshold = 0.95, Training MAE = 0.8193899393081665, Validation MAE = 0.4593322277069092\n",
      "Stock ID = 85, Cosine similarity threshold = 0.95, Training MAE = 0.7504422068595886, Validation MAE = 0.5984170436859131\n",
      "Stock ID = 86, Cosine similarity threshold = 0.95, Training MAE = 0.8101687431335449, Validation MAE = 0.8488187789916992\n",
      "Stock ID = 87, Cosine similarity threshold = 0.95, Training MAE = 0.9521912336349487, Validation MAE = 0.9385086297988892\n",
      "Stock ID = 88, Cosine similarity threshold = 0.95, Training MAE = 0.8809101581573486, Validation MAE = 0.8741289377212524\n",
      "Stock ID = 89, Cosine similarity threshold = 0.95, Training MAE = 0.7830219864845276, Validation MAE = 0.45301809906959534\n",
      "Stock ID = 90, Cosine similarity threshold = 0.95, Training MAE = 0.7456990480422974, Validation MAE = 0.6850332617759705\n",
      "Stock ID = 91, Cosine similarity threshold = 0.95, Training MAE = 0.7933105826377869, Validation MAE = 0.36031705141067505\n",
      "Stock ID = 92, Cosine similarity threshold = 0.95, Training MAE = 0.7299214601516724, Validation MAE = 0.534796416759491\n",
      "Stock ID = 93, Cosine similarity threshold = 0.95, Training MAE = 0.816112756729126, Validation MAE = 0.4910486340522766\n",
      "Stock ID = 94, Cosine similarity threshold = 0.95, Training MAE = 0.7985846996307373, Validation MAE = 0.5734083652496338\n",
      "Stock ID = 95, Cosine similarity threshold = 0.95, Training MAE = 0.9525313973426819, Validation MAE = 0.5528530478477478\n",
      "Stock ID = 96, Cosine similarity threshold = 0.95, Training MAE = 0.9378141760826111, Validation MAE = 0.7528418898582458\n",
      "Stock ID = 97, Cosine similarity threshold = 0.95, Training MAE = 0.9095420241355896, Validation MAE = 0.6692285537719727\n",
      "Stock ID = 98, Cosine similarity threshold = 0.95, Training MAE = 0.8948293328285217, Validation MAE = 0.4837295114994049\n",
      "Stock ID = 99, Cosine similarity threshold = 0.95, Training MAE = 0.8247239589691162, Validation MAE = 0.7731720209121704\n",
      "Stock ID = 100, Cosine similarity threshold = 0.95, Training MAE = 0.9107398390769958, Validation MAE = 0.6701898574829102\n",
      "Stock ID = 101, Cosine similarity threshold = 0.95, Training MAE = 0.8018734455108643, Validation MAE = 0.5990964770317078\n",
      "Stock ID = 102, Cosine similarity threshold = 0.95, Training MAE = 1.2966474294662476, Validation MAE = 1.369349479675293\n",
      "Stock ID = 103, Cosine similarity threshold = 0.95, Training MAE = 0.7765299677848816, Validation MAE = 0.6549846529960632\n",
      "Stock ID = 104, Cosine similarity threshold = 0.95, Training MAE = 0.8827752470970154, Validation MAE = 1.1798020601272583\n",
      "Stock ID = 105, Cosine similarity threshold = 0.95, Training MAE = 0.8357146978378296, Validation MAE = 0.4674590528011322\n",
      "Stock ID = 106, Cosine similarity threshold = 0.95, Training MAE = 0.852321982383728, Validation MAE = 0.4708133637905121\n",
      "Stock ID = 107, Cosine similarity threshold = 0.95, Training MAE = 0.839095950126648, Validation MAE = 0.7311915755271912\n",
      "Stock ID = 108, Cosine similarity threshold = 0.95, Training MAE = 0.9043887853622437, Validation MAE = 0.8279306292533875\n",
      "Stock ID = 109, Cosine similarity threshold = 0.95, Training MAE = 0.7666043639183044, Validation MAE = 0.38189539313316345\n",
      "Stock ID = 110, Cosine similarity threshold = 0.95, Training MAE = 0.8131789565086365, Validation MAE = 0.5866807699203491\n",
      "Stock ID = 111, Cosine similarity threshold = 0.95, Training MAE = 0.7561041116714478, Validation MAE = 0.511420488357544\n",
      "Stock ID = 112, Cosine similarity threshold = 0.95, Training MAE = 0.7579209208488464, Validation MAE = 0.5469393730163574\n",
      "Stock ID = 113, Cosine similarity threshold = 0.95, Training MAE = 0.8590469360351562, Validation MAE = 0.9533568620681763\n",
      "Stock ID = 114, Cosine similarity threshold = 0.95, Training MAE = 0.9016202092170715, Validation MAE = 1.1961729526519775\n",
      "Stock ID = 115, Cosine similarity threshold = 0.95, Training MAE = 0.7458149790763855, Validation MAE = 0.7057032585144043\n",
      "Stock ID = 116, Cosine similarity threshold = 0.95, Training MAE = 1.126497745513916, Validation MAE = 0.9692994356155396\n",
      "Stock ID = 117, Cosine similarity threshold = 0.95, Training MAE = 1.007814884185791, Validation MAE = 0.5208771824836731\n",
      "Stock ID = 118, Cosine similarity threshold = 0.95, Training MAE = 0.8544132709503174, Validation MAE = 0.694174587726593\n",
      "Stock ID = 119, Cosine similarity threshold = 0.95, Training MAE = 0.9227131605148315, Validation MAE = 0.5044625401496887\n",
      "Stock ID = 120, Cosine similarity threshold = 0.95, Training MAE = 0.9025880098342896, Validation MAE = 0.8303623199462891\n",
      "Stock ID = 121, Cosine similarity threshold = 0.95, Training MAE = 0.8438515663146973, Validation MAE = 0.6622830629348755\n",
      "Stock ID = 122, Cosine similarity threshold = 0.95, Training MAE = 0.7991300821304321, Validation MAE = 0.6525087952613831\n",
      "Stock ID = 123, Cosine similarity threshold = 0.95, Training MAE = 0.880975067615509, Validation MAE = 1.0770756006240845\n",
      "Stock ID = 124, Cosine similarity threshold = 0.95, Training MAE = 1.0793988704681396, Validation MAE = 1.1284198760986328\n",
      "Stock ID = 125, Cosine similarity threshold = 0.95, Training MAE = 0.9299162030220032, Validation MAE = 0.7082887887954712\n",
      "Stock ID = 126, Cosine similarity threshold = 0.95, Training MAE = 0.8940339088439941, Validation MAE = 1.4157034158706665\n",
      "Stock ID = 127, Cosine similarity threshold = 0.95, Training MAE = 0.8133981227874756, Validation MAE = 0.6690557599067688\n",
      "Stock ID = 128, Cosine similarity threshold = 0.95, Training MAE = 0.8733794689178467, Validation MAE = 0.6231144070625305\n",
      "Stock ID = 129, Cosine similarity threshold = 0.95, Training MAE = 0.9453544020652771, Validation MAE = 0.6061013340950012\n",
      "Stock ID = 130, Cosine similarity threshold = 0.95, Training MAE = 0.7928402423858643, Validation MAE = 0.532344400882721\n",
      "Stock ID = 131, Cosine similarity threshold = 0.95, Training MAE = 1.0160295963287354, Validation MAE = 0.9178948402404785\n",
      "Stock ID = 132, Cosine similarity threshold = 0.95, Training MAE = 0.8514246940612793, Validation MAE = 1.0078866481781006\n",
      "Stock ID = 133, Cosine similarity threshold = 0.95, Training MAE = 0.8182774186134338, Validation MAE = 0.477817177772522\n",
      "Stock ID = 134, Cosine similarity threshold = 0.95, Training MAE = 0.7892904877662659, Validation MAE = 0.7338575124740601\n",
      "Stock ID = 135, Cosine similarity threshold = 0.95, Training MAE = 0.8855845928192139, Validation MAE = 0.5861068367958069\n",
      "Stock ID = 136, Cosine similarity threshold = 0.95, Training MAE = 0.8243921995162964, Validation MAE = 0.9626411199569702\n",
      "Stock ID = 137, Cosine similarity threshold = 0.95, Training MAE = 1.1001874208450317, Validation MAE = 0.9602630734443665\n",
      "Stock ID = 138, Cosine similarity threshold = 0.95, Training MAE = 0.9004276394844055, Validation MAE = 1.1962757110595703\n",
      "Stock ID = 139, Cosine similarity threshold = 0.95, Training MAE = 0.8567894697189331, Validation MAE = 0.6361379027366638\n",
      "Stock ID = 140, Cosine similarity threshold = 0.95, Training MAE = 1.009549617767334, Validation MAE = 0.7469543218612671\n",
      "Stock ID = 141, Cosine similarity threshold = 0.95, Training MAE = 0.8309450149536133, Validation MAE = 0.9480808973312378\n",
      "Stock ID = 142, Cosine similarity threshold = 0.95, Training MAE = 0.8024129271507263, Validation MAE = 0.4949837327003479\n",
      "Stock ID = 143, Cosine similarity threshold = 0.95, Training MAE = 0.8794435858726501, Validation MAE = 0.49046778678894043\n",
      "Stock ID = 144, Cosine similarity threshold = 0.95, Training MAE = 0.8263475298881531, Validation MAE = 0.7927505970001221\n",
      "Stock ID = 145, Cosine similarity threshold = 0.95, Training MAE = 0.8902262449264526, Validation MAE = 0.4962638020515442\n",
      "Stock ID = 146, Cosine similarity threshold = 0.95, Training MAE = 0.8000273108482361, Validation MAE = 0.7424780130386353\n",
      "Stock ID = 147, Cosine similarity threshold = 0.95, Training MAE = 0.8680920600891113, Validation MAE = 1.1181433200836182\n",
      "Stock ID = 148, Cosine similarity threshold = 0.95, Training MAE = 0.8109904527664185, Validation MAE = 0.7472555637359619\n",
      "Stock ID = 149, Cosine similarity threshold = 0.95, Training MAE = 0.8549811840057373, Validation MAE = 0.5193567276000977\n",
      "Stock ID = 150, Cosine similarity threshold = 0.95, Training MAE = 0.7919914722442627, Validation MAE = 0.4744299650192261\n",
      "Stock ID = 151, Cosine similarity threshold = 0.95, Training MAE = 1.0121126174926758, Validation MAE = 0.9699403047561646\n",
      "Stock ID = 152, Cosine similarity threshold = 0.95, Training MAE = 0.824741780757904, Validation MAE = 0.5304290652275085\n",
      "Stock ID = 153, Cosine similarity threshold = 0.95, Training MAE = 1.14271879196167, Validation MAE = 0.46311071515083313\n",
      "Stock ID = 154, Cosine similarity threshold = 0.95, Training MAE = 0.8886116743087769, Validation MAE = 0.7883775234222412\n",
      "Stock ID = 155, Cosine similarity threshold = 0.95, Training MAE = 0.8541324734687805, Validation MAE = 0.4286075532436371\n",
      "Stock ID = 156, Cosine similarity threshold = 0.95, Training MAE = 1.05106782913208, Validation MAE = 0.5515130162239075\n",
      "Stock ID = 157, Cosine similarity threshold = 0.95, Training MAE = 0.8713768124580383, Validation MAE = 0.5429195761680603\n",
      "Stock ID = 158, Cosine similarity threshold = 0.95, Training MAE = 0.7227324843406677, Validation MAE = 0.5618585348129272\n",
      "Stock ID = 159, Cosine similarity threshold = 0.95, Training MAE = 3.2636055946350098, Validation MAE = 0.8376263976097107\n",
      "Stock ID = 160, Cosine similarity threshold = 0.95, Training MAE = 0.8852183222770691, Validation MAE = 0.8880811333656311\n",
      "Stock ID = 161, Cosine similarity threshold = 0.95, Training MAE = 0.9320746064186096, Validation MAE = 0.8165134191513062\n",
      "Stock ID = 162, Cosine similarity threshold = 0.95, Training MAE = 0.9202786087989807, Validation MAE = 0.897783100605011\n",
      "Stock ID = 163, Cosine similarity threshold = 0.95, Training MAE = 0.7582001090049744, Validation MAE = 0.4384823739528656\n",
      "Stock ID = 164, Cosine similarity threshold = 0.95, Training MAE = 0.7682231068611145, Validation MAE = 0.6454418897628784\n",
      "Stock ID = 165, Cosine similarity threshold = 0.95, Training MAE = 0.8153463006019592, Validation MAE = 0.7477673292160034\n",
      "Stock ID = 166, Cosine similarity threshold = 0.95, Training MAE = 1.0624176263809204, Validation MAE = 0.6024103164672852\n",
      "Stock ID = 167, Cosine similarity threshold = 0.95, Training MAE = 1.1111538410186768, Validation MAE = 0.6994677186012268\n",
      "Stock ID = 168, Cosine similarity threshold = 0.95, Training MAE = 0.9462587833404541, Validation MAE = 0.7933401465415955\n",
      "Stock ID = 169, Cosine similarity threshold = 0.95, Training MAE = 0.9304815530776978, Validation MAE = 0.6039438843727112\n",
      "Stock ID = 170, Cosine similarity threshold = 0.95, Training MAE = 0.8140377402305603, Validation MAE = 0.8004978895187378\n",
      "Stock ID = 171, Cosine similarity threshold = 0.95, Training MAE = 0.8600660562515259, Validation MAE = 0.7927918434143066\n",
      "Stock ID = 172, Cosine similarity threshold = 0.95, Training MAE = 1.2943730354309082, Validation MAE = 0.9075132608413696\n",
      "Stock ID = 173, Cosine similarity threshold = 0.95, Training MAE = 0.8415212631225586, Validation MAE = 0.8990359902381897\n",
      "Stock ID = 174, Cosine similarity threshold = 0.95, Training MAE = 0.6894973516464233, Validation MAE = 0.3002825379371643\n",
      "Stock ID = 175, Cosine similarity threshold = 0.95, Training MAE = 0.8234803676605225, Validation MAE = 0.6208695769309998\n",
      "Stock ID = 176, Cosine similarity threshold = 0.95, Training MAE = 0.7762866616249084, Validation MAE = 0.6818139553070068\n",
      "Stock ID = 177, Cosine similarity threshold = 0.95, Training MAE = 0.8604000210762024, Validation MAE = 0.6549416184425354\n",
      "Stock ID = 178, Cosine similarity threshold = 0.95, Training MAE = 0.788238525390625, Validation MAE = 0.5574681758880615\n",
      "Stock ID = 179, Cosine similarity threshold = 0.95, Training MAE = 0.8346091508865356, Validation MAE = 0.6809923648834229\n",
      "Stock ID = 180, Cosine similarity threshold = 0.95, Training MAE = 0.7747582793235779, Validation MAE = 0.7003347873687744\n",
      "Stock ID = 181, Cosine similarity threshold = 0.95, Training MAE = 0.8414296507835388, Validation MAE = 0.7468650341033936\n",
      "Stock ID = 182, Cosine similarity threshold = 0.95, Training MAE = 0.7854903936386108, Validation MAE = 0.9244170188903809\n",
      "Stock ID = 183, Cosine similarity threshold = 0.95, Training MAE = 0.7767554521560669, Validation MAE = 0.7220613956451416\n",
      "Stock ID = 184, Cosine similarity threshold = 0.95, Training MAE = 0.8732414841651917, Validation MAE = 0.5228534936904907\n",
      "Stock ID = 185, Cosine similarity threshold = 0.95, Training MAE = 3.0495963096618652, Validation MAE = 0.9661267995834351\n",
      "Stock ID = 186, Cosine similarity threshold = 0.95, Training MAE = 0.9305590391159058, Validation MAE = 0.7770194411277771\n",
      "Stock ID = 187, Cosine similarity threshold = 0.95, Training MAE = 0.8323962092399597, Validation MAE = 0.5804766416549683\n",
      "Stock ID = 188, Cosine similarity threshold = 0.95, Training MAE = 0.8004329204559326, Validation MAE = 0.5876975059509277\n",
      "Stock ID = 189, Cosine similarity threshold = 0.95, Training MAE = 0.5337194800376892, Validation MAE = 0.5805308818817139\n",
      "Stock ID = 190, Cosine similarity threshold = 0.95, Training MAE = 0.8887357115745544, Validation MAE = 0.770042896270752\n",
      "Stock ID = 191, Cosine similarity threshold = 0.95, Training MAE = 0.725786566734314, Validation MAE = 0.4612414836883545\n",
      "Stock ID = 192, Cosine similarity threshold = 0.95, Training MAE = 0.7645357251167297, Validation MAE = 0.44793665409088135\n",
      "Stock ID = 193, Cosine similarity threshold = 0.95, Training MAE = 0.9252426028251648, Validation MAE = 0.7753530144691467\n",
      "Stock ID = 194, Cosine similarity threshold = 0.95, Training MAE = 0.8198148608207703, Validation MAE = 0.5134080648422241\n",
      "Stock ID = 195, Cosine similarity threshold = 0.95, Training MAE = 0.8119176030158997, Validation MAE = 0.8312662839889526\n",
      "Stock ID = 196, Cosine similarity threshold = 0.95, Training MAE = 0.8481304049491882, Validation MAE = 0.5946464538574219\n",
      "Stock ID = 197, Cosine similarity threshold = 0.95, Training MAE = 1.0181583166122437, Validation MAE = 1.084992527961731\n",
      "Stock ID = 198, Cosine similarity threshold = 0.95, Training MAE = 0.9346683025360107, Validation MAE = 0.8367197513580322\n",
      "Stock ID = 199, Cosine similarity threshold = 0.95, Training MAE = 0.8746449947357178, Validation MAE = 0.5147013068199158\n"
     ]
    }
   ],
   "source": [
    "print('The MAEs of the models are: -')\n",
    "count1 = 0\n",
    "count2 = 0\n",
    "avg_MAE = 0\n",
    "for curr_stock_id in models_dict.keys():\n",
    "    print(f'Stock ID = {curr_stock_id}, Cosine similarity threshold = {models_dict[curr_stock_id][1]}, Training MAE = {models_dict[curr_stock_id][2]}, Validation MAE = {models_dict[curr_stock_id][3]}')\n",
    "\n",
    "    #Check the number of stocks predictions for which have a validation MAE of less than 5.\n",
    "    if models_dict[curr_stock_id][3] < 4:\n",
    "        count1 += 1\n",
    "\n",
    "    if models_dict[curr_stock_id][3] < 5:\n",
    "        count2 += 1\n",
    "    \n",
    "    avg_MAE += models_dict[curr_stock_id][3]\n",
    "\n",
    "avg_MAE = avg_MAE/len(models_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stocks predictions for which have a validation MAE of less than 4 =  200\n",
      "Number of stocks predictions for which have a validation MAE of less than 5 =  200\n",
      "Average validation MAE =  0.6868573960661888\n"
     ]
    }
   ],
   "source": [
    "print('Number of stocks predictions for which have a validation MAE of less than 4 = ', count1)\n",
    "print('Number of stocks predictions for which have a validation MAE of less than 5 = ', count2)\n",
    "print('Average validation MAE = ', avg_MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 7056235,
     "sourceId": 57891,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30627,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6253.780111,
   "end_time": "2023-12-09T14:44:23.773902",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-09T13:00:09.993791",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
